{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6822588f",
   "metadata": {},
   "source": [
    "# Generating Answers\n",
    "In ths we will add a generation step using a llm at the end of the model. In this we will get the answer isntead of a search result.\n",
    "\n",
    "This is where use build the apps where use chat with a docuemnt or a book or an articel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee9744da-72bf-4228-a75c-d98648eb13f9",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "question = \"Are side projects important when you are starting to learn about AI?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918129d6",
   "metadata": {
    "height": 30
   },
   "source": [
    "we can use langchain or lamma index to import pdf. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c644ca0-e1d2-42e4-a668-12e3c80413ed",
   "metadata": {
    "height": 914
   },
   "outputs": [],
   "source": [
    "# We have encapsulated different articels text togheter.\n",
    "text = \"\"\"\n",
    "The rapid rise of AI has led to a rapid rise in AI jobs, and many people are building exciting careers in this field. A career is a decades-long journey, and the path is not always straightforward. Over many years, I’ve been privileged to see thousands of students as well as engineers in companies large and small navigate careers in AI. In this and the next few letters, I’d like to share a few thoughts that might be useful in charting your own course.\n",
    "\n",
    "Three key steps of career growth are learning (to gain technical and other skills), working on projects (to deepen skills, build a portfolio, and create impact) and searching for a job. These steps stack on top of each other:\n",
    "\n",
    "Initially, you focus on gaining foundational technical skills.\n",
    "After having gained foundational skills, you lean into project work. During this period, you’ll probably keep learning.\n",
    "Later, you might occasionally carry out a job search. Throughout this process, you’ll probably continue to learn and work on meaningful projects.\n",
    "These phases apply in a wide range of professions, but AI involves unique elements. For example:\n",
    "\n",
    "AI is nascent, and many technologies are still evolving. While the foundations of machine learning and deep learning are maturing — and coursework is an efficient way to master them — beyond these foundations, keeping up-to-date with changing technology is more important in AI than fields that are more mature.\n",
    "Project work often means working with stakeholders who lack expertise in AI. This can make it challenging to find a suitable project, estimate the project’s timeline and return on investment, and set expectations. In addition, the highly iterative nature of AI projects leads to special challenges in project management: How can you come up with a plan for building a system when you don’t know in advance how long it will take to achieve the target accuracy? Even after the system has hit the target, further iteration may be necessary to address post-deployment drift.\n",
    "While searching for a job in AI can be similar to searching for a job in other sectors, there are some differences. Many companies are still trying to figure out which AI skills they need and how to hire people who have them. Things you’ve worked on may be significantly different than anything your interviewer has seen, and you’re more likely to have to educate potential employers about some elements of your work.\n",
    "Throughout these steps, a supportive community is a big help. Having a group of friends and allies who can help you — and whom you strive to help — makes the path easier. This is true whether you’re taking your first steps or you’ve been on the journey for years.\n",
    "\n",
    "I’m excited to work with all of you to grow the global AI community, and that includes helping everyone in our community develop their careers. I’ll dive more deeply into these topics in the next few weeks.\n",
    "\n",
    "Last week, I wrote about key steps for building a career in AI: learning technical skills, doing project work, and searching for a job, all of which is supported by being part of a community. In this letter, I’d like to dive more deeply into the first step.\n",
    "\n",
    "More papers have been published on AI than any person can read in a lifetime. So, in your efforts to learn, it’s critical to prioritize topic selection. I believe the most important topics for a technical career in machine learning are:\n",
    "\n",
    "Foundational machine learning skills. For example, it’s important to understand models such as linear regression, logistic regression, neural networks, decision trees, clustering, and anomaly detection. Beyond specific models, it’s even more important to understand the core concepts behind how and why machine learning works, such as bias/variance, cost functions, regularization, optimization algorithms, and error analysis.\n",
    "Deep learning. This has become such a large fraction of machine learning that it’s hard to excel in the field without some understanding of it! It’s valuable to know the basics of neural networks, practical skills for making them work (such as hyperparameter tuning), convolutional networks, sequence models, and transformers.\n",
    "Math relevant to machine learning. Key areas include linear algebra (vectors, matrices, and various manipulations of them) as well as probability and statistics (including discrete and continuous probability, standard probability distributions, basic rules such as independence and Bayes rule, and hypothesis testing). In addition, exploratory data analysis (EDA) — using visualizations and other methods to systematically explore a dataset — is an underrated skill. I’ve found EDA particularly useful in data-centric AI development, where analyzing errors and gaining insights can really help drive progress! Finally, a basic intuitive understanding of calculus will also help. In a previous letter, I described how the math needed to do machine learning well has been changing. For instance, although some tasks require calculus, improved automatic differentiation software makes it possible to invent and implement new neural network architectures without doing any calculus. This was almost impossible a decade ago.\n",
    "Software development. While you can get a job and make huge contributions with only machine learning modeling skills, your job opportunities will increase if you can also write good software to implement complex AI systems. These skills include programming fundamentals, data structures (especially those that relate to machine learning, such as data frames), algorithms (including those related to databases and data manipulation), software design, familiarity with Python, and familiarity with key libraries such as TensorFlow or PyTorch, and scikit-learn.\n",
    "This is a lot to learn! Even after you master everything in this list, I hope you’ll keep learning and continue to deepen your technical knowledge. I’ve known many machine learning engineers who benefitted from deeper skills in an application area such as natural language processing or computer vision, or in a technology area such as probabilistic graphical models or building scalable software systems.\n",
    "\n",
    "How do you gain these skills? There’s a lot of good content on the internet, and in theory reading dozens of web pages could work. But when the goal is deep understanding, reading disjointed web pages is inefficient because they tend to repeat each other, use inconsistent terminology (which slows you down), vary in quality, and leave gaps. That’s why a good course — in which a body of material has been organized into a coherent and logical form — is often the most time-efficient way to master a meaningful body of knowledge. When you’ve absorbed the knowledge available in courses, you can switch over to research papers and other resources.\n",
    "\n",
    "Finally, keep in mind that no one can cram everything they need to know over a weekend or even a month. Everyone I know who’s great at machine learning is a lifelong learner. In fact, given how quickly our field is changing, there’s little choice but to keep learning if you want to keep up. How can you maintain a steady pace of learning for years? I’ve written about the value of habits. If you cultivate the habit of learning a little bit every week, you can make significant progress with what feels like less effort.\n",
    "\n",
    "In the last two letters, I wrote about developing a career in AI and shared tips for gaining technical skills. This time, I’d like to discuss an important step in building a career: project work.\n",
    "\n",
    "It goes without saying that we should only work on projects that are responsible and ethical, and that benefit people. But those limits leave a large variety to choose from. I wrote previously about how to identify and scope AI projects. This and next week’s letter have a different emphasis: picking and executing projects with an eye toward career development.\n",
    "\n",
    "A fruitful career will include many projects, hopefully growing in scope, complexity, and impact over time. Thus, it is fine to start small. Use early projects to learn and gradually step up to bigger projects as your skills grow.\n",
    "\n",
    "When you’re starting out, don’t expect others to hand great ideas or resources to you on a platter. Many people start by working on small projects in their spare time. With initial successes — even small ones — under your belt, your growing skills increase your ability to come up with better ideas, and it becomes easier to persuade others to help you step up to bigger projects.\n",
    "\n",
    "What if you don’t have any project ideas? Here are a few ways to generate them:\n",
    "\n",
    "Join existing projects. If you find someone else with an idea, ask to join their project.\n",
    "Keep reading and talking to people. I come up with new ideas whenever I spend a lot of time reading, taking courses, or talking with domain experts. I’m confident that you will, too.\n",
    "Focus on an application area. Many researchers are trying to advance basic AI technology — say, by inventing the next generation of transformers or further scaling up language models — so, while this is an exciting direction, it is hard. But the variety of applications to which machine learning has not yet been applied is vast! I’m fortunate to have been able to apply neural networks to everything from autonomous helicopter flight to online advertising, partly because I jumped in when relatively few people were working on those applications. If your company or school cares about a particular application, explore the possibilities for machine learning. That can give you a first look at a potentially creative application — one where you can do unique work — that no one else has done yet.\n",
    "Develop a side hustle. Even if you have a full-time job, a fun project that may or may not develop into something bigger can stir the creative juices and strengthen bonds with collaborators. When I was a full-time professor, working on online education wasn’t part of my “job” (which was doing research and teaching classes). It was a fun hobby that I often worked on out of passion for education. My early experiences recording videos at home helped me later in working on online education in a more substantive way. Silicon Valley abounds with stories of startups that started as side projects. So long as it doesn’t create a conflict with your employer, these projects can be a stepping stone to something significant.\n",
    "Given a few project ideas, which one should you jump into? Here’s a quick checklist of factors to consider:\n",
    "\n",
    "Will the project help you grow technically? Ideally, it should be challenging enough to stretch your skills but not so hard that you have little chance of success. This will put you on a path toward mastering ever-greater technical complexity.\n",
    "Do you have good teammates to work with? If not, are there people you can discuss things with? We learn a lot from the people around us, and good collaborators will have a huge impact on your growth.\n",
    "Can it be a stepping stone? If the project is successful, will its technical complexity and/or business impact make it a meaningful stepping stone to larger projects? (If the project is bigger than those you’ve worked on before, there’s a good chance it could be such a stepping stone.)\n",
    "Finally, avoid analysis paralysis. It doesn’t make sense to spend a month deciding whether to work on a project that would take a week to complete. You'll work on multiple projects over the course of your career, so you’ll have ample opportunity to refine your thinking on what’s worthwhile. Given the huge number of possible AI projects, rather than the conventional “ready, aim, fire” approach, you can accelerate your progress with “ready, fire, aim.”\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f464683c",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Load needed API keys and relevant Python libaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ad188a7-9b22-41cf-be13-9b9aa88b1d8b",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b8e6539",
   "metadata": {
    "height": 98
   },
   "outputs": [],
   "source": [
    "import cohere\n",
    "\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b2d46b",
   "metadata": {},
   "source": [
    "## Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6048a9ee-d489-437c-8dd6-38c228b59b06",
   "metadata": {
    "height": 98
   },
   "outputs": [],
   "source": [
    "# Split into a list of paragraphs\n",
    "texts = text.split('\\n\\n')\n",
    "\n",
    "# Clean up to remove empty spaces and new lines\n",
    "texts = np.array([t.strip(' \\n') for t in texts if t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ce659d9-b665-4559-804e-509001ee39e7",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['The rapid rise of AI has led to a rapid rise in AI jobs, and many people are building exciting careers in this field. A career is a decades-long journey, and the path is not always straightforward. Over many years, I’ve been privileged to see thousands of students as well as engineers in companies large and small navigate careers in AI. In this and the next few letters, I’d like to share a few thoughts that might be useful in charting your own course.',\n",
       "       'Three key steps of career growth are learning (to gain technical and other skills), working on projects (to deepen skills, build a portfolio, and create impact) and searching for a job. These steps stack on top of each other:',\n",
       "       'Initially, you focus on gaining foundational technical skills.\\nAfter having gained foundational skills, you lean into project work. During this period, you’ll probably keep learning.\\nLater, you might occasionally carry out a job search. Throughout this process, you’ll probably continue to learn and work on meaningful projects.\\nThese phases apply in a wide range of professions, but AI involves unique elements. For example:'],\n",
       "      dtype='<U2738')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets see first three chunks\n",
    "texts[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "894c03da",
   "metadata": {},
   "source": [
    "## Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9d1086f-2713-41c5-9f60-049d25ad2b4b",
   "metadata": {
    "height": 132
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "default model on embed will be deprecated in the future, please specify a model in the request.\n",
      "default model on embed will be deprecated in the future, please specify a model in the request.\n",
      "default model on embed will be deprecated in the future, please specify a model in the request.\n",
      "default model on embed will be deprecated in the future, please specify a model in the request.\n",
      "default model on embed will be deprecated in the future, please specify a model in the request.\n",
      "default model on embed will be deprecated in the future, please specify a model in the request.\n",
      "default model on embed will be deprecated in the future, please specify a model in the request.\n",
      "default model on embed will be deprecated in the future, please specify a model in the request.\n",
      "default model on embed will be deprecated in the future, please specify a model in the request.\n",
      "default model on embed will be deprecated in the future, please specify a model in the request.\n"
     ]
    }
   ],
   "source": [
    "co = cohere.Client(os.environ['COHERE_API_KEY'])\n",
    "\n",
    "# Get the embeddings\n",
    "response = co.embed(\n",
    "    texts=texts.tolist(),\n",
    ").embeddings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ef402c",
   "metadata": {},
   "source": [
    "## Build a search index\n",
    "Building symentaic search index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc497e02-fa39-4357-a715-45df1e88e162",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "from annoy import AnnoyIndex # vector search library\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a0a49d5-bfb7-4267-81f3-70df49d604be",
   "metadata": {
    "height": 200
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the dimensions of the embeddings\n",
    "embeds = np.array(response)\n",
    "\n",
    "# Create the search index, pass the size of embedding\n",
    "search_index = AnnoyIndex(embeds.shape[1], 'angular')\n",
    "# Add all the vectors to the search index\n",
    "for i in range(len(embeds)):\n",
    "    search_index.add_item(i, embeds[i])\n",
    "\n",
    "search_index.build(10) # 10 trees\n",
    "search_index.save('test.ann')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13876608",
   "metadata": {},
   "source": [
    "## Searching Articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c428f6ac-cf88-4914-9813-eefbad552a8d",
   "metadata": {
    "height": 217
   },
   "outputs": [],
   "source": [
    "# define a function to reun a query\n",
    "def search_andrews_article(query):\n",
    "    # Get the query's embedding\n",
    "    query_embed = co.embed(texts=[query]).embeddings\n",
    "    \n",
    "    # Retrieve the nearest neighbors\n",
    "    similar_item_ids = search_index.get_nns_by_vector(query_embed[0],\n",
    "                                                    10,\n",
    "                                                  include_distances=True)\n",
    "\n",
    "    search_results = texts[similar_item_ids[0]]\n",
    "    \n",
    "    return search_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fa6ce113-6444-4517-9bc4-03552a469a21",
   "metadata": {
    "height": 167
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Join existing projects. If you find someone else with an idea, ask to join their project.\n",
      "Keep reading and talking to people. I come up with new ideas whenever I spend a lot of time reading, taking courses, or talking with domain experts. I’m confident that you will, too.\n",
      "Focus on an application area. Many researchers are trying to advance basic AI technology — say, by inventing the next generation of transformers or further scaling up language models — so, while this is an exciting direction, it is hard. But the variety of applications to which machine learning has not yet been applied is vast! I’m fortunate to have been able to apply neural networks to everything from autonomous helicopter flight to online advertising, partly because I jumped in when relatively few people were working on those applications. If your company or school cares about a particular application, explore the possibilities for machine learning. That can give you a first look at a potentially creative application — one where you can do unique work — that no one else has done yet.\n",
      "Develop a side hustle. Even if you have a full-time job, a fun project that may or may not develop into something bigger can stir the creative juices and strengthen bonds with collaborators. When I was a full-time professor, working on online education wasn’t part of my “job” (which was doing research and teaching classes). It was a fun hobby that I often worked on out of passion for education. My early experiences recording videos at home helped me later in working on online education in a more substantive way. Silicon Valley abounds with stories of startups that started as side projects. So long as it doesn’t create a conflict with your employer, these projects can be a stepping stone to something significant.\n",
      "Given a few project ideas, which one should you jump into? Here’s a quick checklist of factors to consider:\n"
     ]
    }
   ],
   "source": [
    "# Ask search sytem a query\n",
    "results = search_andrews_article(\n",
    "    \"Are side projects a good idea when trying to build a career in AI?\"\n",
    ")\n",
    "\n",
    "print(results[0])\n",
    "\n",
    "# this will give a long paragrph, but there is an aswer, we will extract answer later."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0fcf20a",
   "metadata": {},
   "source": [
    "## Generating Answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c63a5f76-d54d-46f3-ac04-1213031ab6e7",
   "metadata": {
    "height": 489
   },
   "outputs": [],
   "source": [
    "\n",
    "def ask_andrews_article(question, num_generations=1):\n",
    "    \n",
    "    # Search the text archive. Get the relevant text htat we generated above\n",
    "    results = search_andrews_article(question)\n",
    "\n",
    "    # Get the top result\n",
    "    context = results[0]\n",
    "\n",
    "    # Prepare the prompt. You can provide more context.\n",
    "    prompt = f\"\"\"\n",
    "    Excerpt from the article titled \"How to Build a Career in AI\" \n",
    "    by Andrew Ng: \n",
    "    {context}\n",
    "    Question: {question}\n",
    "    \n",
    "    Extract the answer of the question from the text provided. \n",
    "    If the text doesn't contain the answer, \n",
    "    reply that the answer is not available.\"\"\"\n",
    "\n",
    "    prediction = co.generate(\n",
    "        prompt=prompt,\n",
    "        max_tokens=70,\n",
    "        model=\"command-nightly\", # latest generation model\n",
    "        temperature=0.5,\n",
    "        num_generations=num_generations\n",
    "    )\n",
    "\n",
    "    return prediction.generations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "20b4f4c6-dc1a-4837-a131-4c3d13d6d4c5",
   "metadata": {
    "height": 115
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "unknown field: parameter model is not a valid field\n"
     ]
    },
    {
     "ename": "CohereAPIError",
     "evalue": "invalid request: generate API is not supported for model 'command-nightly'. Please use the chat API instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCohereAPIError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Instead of search we use generative answer\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mask_andrews_article\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mAre side projects a good idea when trying to build a career in AI?\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \n\u001b[1;32m      5\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(results[\u001b[38;5;241m0\u001b[39m])\n",
      "Cell \u001b[0;32mIn[18], line 20\u001b[0m, in \u001b[0;36mask_andrews_article\u001b[0;34m(question, num_generations)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Prepare the prompt. You can provide more context.\u001b[39;00m\n\u001b[1;32m     10\u001b[0m prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;124mExcerpt from the article titled \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHow to Build a Career in AI\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;124mby Andrew Ng: \u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;124mIf the text doesn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt contain the answer, \u001b[39m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;124mreply that the answer is not available.\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m---> 20\u001b[0m prediction \u001b[38;5;241m=\u001b[39m \u001b[43mco\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m70\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcommand-nightly\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_generations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_generations\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m prediction\u001b[38;5;241m.\u001b[39mgenerations\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/cohere/client.py:221\u001b[0m, in \u001b[0;36mClient.generate\u001b[0;34m(self, prompt, prompt_vars, model, preset, num_generations, max_tokens, temperature, k, p, frequency_penalty, presence_penalty, end_sequences, stop_sequences, return_likelihoods, truncate, logit_bias, stream)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Generate endpoint.\u001b[39;00m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;124;03mSee https://docs.cohere.ai/reference/generate for advanced arguments\u001b[39;00m\n\u001b[1;32m    166\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;124;03m        >>>     print(token)\u001b[39;00m\n\u001b[1;32m    201\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    202\u001b[0m json_body \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m: model,\n\u001b[1;32m    204\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m\"\u001b[39m: prompt,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m: stream,\n\u001b[1;32m    220\u001b[0m }\n\u001b[0;32m--> 221\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcohere\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGENERATE_URL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjson_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stream:\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m StreamingGenerations(response)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/cohere/client.py:870\u001b[0m, in \u001b[0;36mClient._request\u001b[0;34m(self, endpoint, json, files, method, stream, params)\u001b[0m\n\u001b[1;32m    867\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m jsonlib\u001b[38;5;241m.\u001b[39mdecoder\u001b[38;5;241m.\u001b[39mJSONDecodeError:  \u001b[38;5;66;03m# CohereAPIError will capture status\u001b[39;00m\n\u001b[1;32m    868\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m CohereAPIError\u001b[38;5;241m.\u001b[39mfrom_response(response, message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to decode json body: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 870\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson_response\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstatus_code\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    871\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m json_response\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/cohere/client.py:812\u001b[0m, in \u001b[0;36mClient._check_response\u001b[0;34m(self, json_response, headers, status_code)\u001b[0m\n\u001b[1;32m    810\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarning(headers[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX-API-Warning\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    811\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m json_response:  \u001b[38;5;66;03m# has errors\u001b[39;00m\n\u001b[0;32m--> 812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CohereAPIError(\n\u001b[1;32m    813\u001b[0m         message\u001b[38;5;241m=\u001b[39mjson_response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    814\u001b[0m         http_status\u001b[38;5;241m=\u001b[39mstatus_code,\n\u001b[1;32m    815\u001b[0m         headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[1;32m    816\u001b[0m     )\n\u001b[1;32m    817\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;241m400\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m status_code \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m500\u001b[39m:\n\u001b[1;32m    818\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CohereAPIError(\n\u001b[1;32m    819\u001b[0m         message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnexpected client error (status \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mjson_response\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    820\u001b[0m         http_status\u001b[38;5;241m=\u001b[39mstatus_code,\n\u001b[1;32m    821\u001b[0m         headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[1;32m    822\u001b[0m     )\n",
      "\u001b[0;31mCohereAPIError\u001b[0m: invalid request: generate API is not supported for model 'command-nightly'. Please use the chat API instead"
     ]
    }
   ],
   "source": [
    "# Instead of search we use generative answer\n",
    "results = ask_andrews_article(\n",
    "    \"Are side projects a good idea when trying to build a career in AI?\",\n",
    "\n",
    ")\n",
    "\n",
    "print(results[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bce01204-2186-4cbc-a97a-2dd62f2dc46b",
   "metadata": {
    "height": 149
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "unknown field: parameter model is not a valid field\n"
     ]
    },
    {
     "ename": "CohereAPIError",
     "evalue": "invalid request: generate API is not supported for model 'command-nightly'. Please use the chat API instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCohereAPIError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mask_andrews_article\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mAre side projects a good idea when trying to build a career in AI?\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_generations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\n\u001b[1;32m      4\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m gen \u001b[38;5;129;01min\u001b[39;00m results:\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(gen)\n",
      "Cell \u001b[0;32mIn[15], line 20\u001b[0m, in \u001b[0;36mask_andrews_article\u001b[0;34m(question, num_generations)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Prepare the prompt. You can provide more context.\u001b[39;00m\n\u001b[1;32m     10\u001b[0m prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;124mExcerpt from the article titled \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHow to Build a Career in AI\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;124mby Andrew Ng: \u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;124mIf the text doesn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt contain the answer, \u001b[39m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;124mreply that the answer is not available.\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m---> 20\u001b[0m prediction \u001b[38;5;241m=\u001b[39m \u001b[43mco\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m70\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcommand-nightly\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_generations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_generations\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m prediction\u001b[38;5;241m.\u001b[39mgenerations\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/cohere/client.py:221\u001b[0m, in \u001b[0;36mClient.generate\u001b[0;34m(self, prompt, prompt_vars, model, preset, num_generations, max_tokens, temperature, k, p, frequency_penalty, presence_penalty, end_sequences, stop_sequences, return_likelihoods, truncate, logit_bias, stream)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Generate endpoint.\u001b[39;00m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;124;03mSee https://docs.cohere.ai/reference/generate for advanced arguments\u001b[39;00m\n\u001b[1;32m    166\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;124;03m        >>>     print(token)\u001b[39;00m\n\u001b[1;32m    201\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    202\u001b[0m json_body \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m: model,\n\u001b[1;32m    204\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m\"\u001b[39m: prompt,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m: stream,\n\u001b[1;32m    220\u001b[0m }\n\u001b[0;32m--> 221\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcohere\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGENERATE_URL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjson_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stream:\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m StreamingGenerations(response)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/cohere/client.py:870\u001b[0m, in \u001b[0;36mClient._request\u001b[0;34m(self, endpoint, json, files, method, stream, params)\u001b[0m\n\u001b[1;32m    867\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m jsonlib\u001b[38;5;241m.\u001b[39mdecoder\u001b[38;5;241m.\u001b[39mJSONDecodeError:  \u001b[38;5;66;03m# CohereAPIError will capture status\u001b[39;00m\n\u001b[1;32m    868\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m CohereAPIError\u001b[38;5;241m.\u001b[39mfrom_response(response, message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to decode json body: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 870\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson_response\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstatus_code\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    871\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m json_response\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/cohere/client.py:812\u001b[0m, in \u001b[0;36mClient._check_response\u001b[0;34m(self, json_response, headers, status_code)\u001b[0m\n\u001b[1;32m    810\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarning(headers[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX-API-Warning\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    811\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m json_response:  \u001b[38;5;66;03m# has errors\u001b[39;00m\n\u001b[0;32m--> 812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CohereAPIError(\n\u001b[1;32m    813\u001b[0m         message\u001b[38;5;241m=\u001b[39mjson_response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    814\u001b[0m         http_status\u001b[38;5;241m=\u001b[39mstatus_code,\n\u001b[1;32m    815\u001b[0m         headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[1;32m    816\u001b[0m     )\n\u001b[1;32m    817\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;241m400\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m status_code \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m500\u001b[39m:\n\u001b[1;32m    818\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CohereAPIError(\n\u001b[1;32m    819\u001b[0m         message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnexpected client error (status \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mjson_response\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    820\u001b[0m         http_status\u001b[38;5;241m=\u001b[39mstatus_code,\n\u001b[1;32m    821\u001b[0m         headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[1;32m    822\u001b[0m     )\n",
      "\u001b[0;31mCohereAPIError\u001b[0m: invalid request: generate API is not supported for model 'command-nightly'. Please use the chat API instead"
     ]
    }
   ],
   "source": [
    "results = ask_andrews_article(\n",
    "    \"Are side projects a good idea when trying to build a career in AI?\",\n",
    "    num_generations=3\n",
    ")\n",
    "\n",
    "for gen in results:\n",
    "    print(gen)\n",
    "    print('--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "094a01b6-0230-4ab2-8df9-9e1fad39f44d",
   "metadata": {
    "height": 98
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "unknown field: parameter model is not a valid field\n"
     ]
    },
    {
     "ename": "CohereAPIError",
     "evalue": "invalid request: generate API is not supported for model 'command-nightly'. Please use the chat API instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCohereAPIError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mask_andrews_article\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mWhat is the most viewed televised event?\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_generations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\n\u001b[1;32m      4\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[18], line 20\u001b[0m, in \u001b[0;36mask_andrews_article\u001b[0;34m(question, num_generations)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Prepare the prompt. You can provide more context.\u001b[39;00m\n\u001b[1;32m     10\u001b[0m prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;124mExcerpt from the article titled \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHow to Build a Career in AI\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;124mby Andrew Ng: \u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;124mIf the text doesn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt contain the answer, \u001b[39m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;124mreply that the answer is not available.\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m---> 20\u001b[0m prediction \u001b[38;5;241m=\u001b[39m \u001b[43mco\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m70\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcommand-nightly\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_generations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_generations\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m prediction\u001b[38;5;241m.\u001b[39mgenerations\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/cohere/client.py:221\u001b[0m, in \u001b[0;36mClient.generate\u001b[0;34m(self, prompt, prompt_vars, model, preset, num_generations, max_tokens, temperature, k, p, frequency_penalty, presence_penalty, end_sequences, stop_sequences, return_likelihoods, truncate, logit_bias, stream)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Generate endpoint.\u001b[39;00m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;124;03mSee https://docs.cohere.ai/reference/generate for advanced arguments\u001b[39;00m\n\u001b[1;32m    166\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;124;03m        >>>     print(token)\u001b[39;00m\n\u001b[1;32m    201\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    202\u001b[0m json_body \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m: model,\n\u001b[1;32m    204\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m\"\u001b[39m: prompt,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m: stream,\n\u001b[1;32m    220\u001b[0m }\n\u001b[0;32m--> 221\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcohere\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGENERATE_URL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjson_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stream:\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m StreamingGenerations(response)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/cohere/client.py:870\u001b[0m, in \u001b[0;36mClient._request\u001b[0;34m(self, endpoint, json, files, method, stream, params)\u001b[0m\n\u001b[1;32m    867\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m jsonlib\u001b[38;5;241m.\u001b[39mdecoder\u001b[38;5;241m.\u001b[39mJSONDecodeError:  \u001b[38;5;66;03m# CohereAPIError will capture status\u001b[39;00m\n\u001b[1;32m    868\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m CohereAPIError\u001b[38;5;241m.\u001b[39mfrom_response(response, message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to decode json body: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 870\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson_response\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstatus_code\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    871\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m json_response\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/cohere/client.py:812\u001b[0m, in \u001b[0;36mClient._check_response\u001b[0;34m(self, json_response, headers, status_code)\u001b[0m\n\u001b[1;32m    810\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarning(headers[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX-API-Warning\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    811\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m json_response:  \u001b[38;5;66;03m# has errors\u001b[39;00m\n\u001b[0;32m--> 812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CohereAPIError(\n\u001b[1;32m    813\u001b[0m         message\u001b[38;5;241m=\u001b[39mjson_response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    814\u001b[0m         http_status\u001b[38;5;241m=\u001b[39mstatus_code,\n\u001b[1;32m    815\u001b[0m         headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[1;32m    816\u001b[0m     )\n\u001b[1;32m    817\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;241m400\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m status_code \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m500\u001b[39m:\n\u001b[1;32m    818\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CohereAPIError(\n\u001b[1;32m    819\u001b[0m         message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnexpected client error (status \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mjson_response\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    820\u001b[0m         http_status\u001b[38;5;241m=\u001b[39mstatus_code,\n\u001b[1;32m    821\u001b[0m         headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[1;32m    822\u001b[0m     )\n",
      "\u001b[0;31mCohereAPIError\u001b[0m: invalid request: generate API is not supported for model 'command-nightly'. Please use the chat API instead"
     ]
    }
   ],
   "source": [
    "results = ask_andrews_article(\n",
    "    \"What is the most viewed televised event?\",\n",
    "    num_generations=5\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6bf3497f-a988-4aab-9dfb-dcf65bdd379b",
   "metadata": {
    "height": 64
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Join existing projects. If you find someone else with an idea, ask to join their project.\n",
      "Keep reading and talking to people. I come up with new ideas whenever I spend a lot of time reading, taking courses, or talking with domain experts. I’m confident that you will, too.\n",
      "Focus on an application area. Many researchers are trying to advance basic AI technology — say, by inventing the next generation of transformers or further scaling up language models — so, while this is an exciting direction, it is hard. But the variety of applications to which machine learning has not yet been applied is vast! I’m fortunate to have been able to apply neural networks to everything from autonomous helicopter flight to online advertising, partly because I jumped in when relatively few people were working on those applications. If your company or school cares about a particular application, explore the possibilities for machine learning. That can give you a first look at a potentially creative application — one where you can do unique work — that no one else has done yet.\n",
      "Develop a side hustle. Even if you have a full-time job, a fun project that may or may not develop into something bigger can stir the creative juices and strengthen bonds with collaborators. When I was a full-time professor, working on online education wasn’t part of my “job” (which was doing research and teaching classes). It was a fun hobby that I often worked on out of passion for education. My early experiences recording videos at home helped me later in working on online education in a more substantive way. Silicon Valley abounds with stories of startups that started as side projects. So long as it doesn’t create a conflict with your employer, these projects can be a stepping stone to something significant.\n",
      "Given a few project ideas, which one should you jump into? Here’s a quick checklist of factors to consider:\n",
      "--\n",
      "In the last two letters, I wrote about developing a career in AI and shared tips for gaining technical skills. This time, I’d like to discuss an important step in building a career: project work.\n",
      "--\n",
      "AI is nascent, and many technologies are still evolving. While the foundations of machine learning and deep learning are maturing — and coursework is an efficient way to master them — beyond these foundations, keeping up-to-date with changing technology is more important in AI than fields that are more mature.\n",
      "Project work often means working with stakeholders who lack expertise in AI. This can make it challenging to find a suitable project, estimate the project’s timeline and return on investment, and set expectations. In addition, the highly iterative nature of AI projects leads to special challenges in project management: How can you come up with a plan for building a system when you don’t know in advance how long it will take to achieve the target accuracy? Even after the system has hit the target, further iteration may be necessary to address post-deployment drift.\n",
      "While searching for a job in AI can be similar to searching for a job in other sectors, there are some differences. Many companies are still trying to figure out which AI skills they need and how to hire people who have them. Things you’ve worked on may be significantly different than anything your interviewer has seen, and you’re more likely to have to educate potential employers about some elements of your work.\n",
      "Throughout these steps, a supportive community is a big help. Having a group of friends and allies who can help you — and whom you strive to help — makes the path easier. This is true whether you’re taking your first steps or you’ve been on the journey for years.\n",
      "--\n",
      "A fruitful career will include many projects, hopefully growing in scope, complexity, and impact over time. Thus, it is fine to start small. Use early projects to learn and gradually step up to bigger projects as your skills grow.\n",
      "--\n",
      "Will the project help you grow technically? Ideally, it should be challenging enough to stretch your skills but not so hard that you have little chance of success. This will put you on a path toward mastering ever-greater technical complexity.\n",
      "Do you have good teammates to work with? If not, are there people you can discuss things with? We learn a lot from the people around us, and good collaborators will have a huge impact on your growth.\n",
      "Can it be a stepping stone? If the project is successful, will its technical complexity and/or business impact make it a meaningful stepping stone to larger projects? (If the project is bigger than those you’ve worked on before, there’s a good chance it could be such a stepping stone.)\n",
      "Finally, avoid analysis paralysis. It doesn’t make sense to spend a month deciding whether to work on a project that would take a week to complete. You'll work on multiple projects over the course of your career, so you’ll have ample opportunity to refine your thinking on what’s worthwhile. Given the huge number of possible AI projects, rather than the conventional “ready, aim, fire” approach, you can accelerate your progress with “ready, fire, aim.”\n",
      "--\n",
      "It goes without saying that we should only work on projects that are responsible and ethical, and that benefit people. But those limits leave a large variety to choose from. I wrote previously about how to identify and scope AI projects. This and next week’s letter have a different emphasis: picking and executing projects with an eye toward career development.\n",
      "--\n",
      "When you’re starting out, don’t expect others to hand great ideas or resources to you on a platter. Many people start by working on small projects in their spare time. With initial successes — even small ones — under your belt, your growing skills increase your ability to come up with better ideas, and it becomes easier to persuade others to help you step up to bigger projects.\n",
      "--\n",
      "Last week, I wrote about key steps for building a career in AI: learning technical skills, doing project work, and searching for a job, all of which is supported by being part of a community. In this letter, I’d like to dive more deeply into the first step.\n",
      "--\n",
      "The rapid rise of AI has led to a rapid rise in AI jobs, and many people are building exciting careers in this field. A career is a decades-long journey, and the path is not always straightforward. Over many years, I’ve been privileged to see thousands of students as well as engineers in companies large and small navigate careers in AI. In this and the next few letters, I’d like to share a few thoughts that might be useful in charting your own course.\n",
      "--\n",
      "Initially, you focus on gaining foundational technical skills.\n",
      "After having gained foundational skills, you lean into project work. During this period, you’ll probably keep learning.\n",
      "Later, you might occasionally carry out a job search. Throughout this process, you’ll probably continue to learn and work on meaningful projects.\n",
      "These phases apply in a wide range of professions, but AI involves unique elements. For example:\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "for gen in results:\n",
    "    print(gen)\n",
    "    print('--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2f03ac-2e99-4442-a386-db9163c784db",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c65f0a8-a601-4029-a79e-b0005b9d3958",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff147686-9271-4fb4-859c-693b6db4a804",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cdfa56b-3a2c-41f5-90e4-a716dd3480f0",
   "metadata": {
    "height": 445
   },
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "Fat ray tomography addresses limitations of traditional traveltime tomography by considering the width of seismic wave paths, resembling the first Fresnel zone, instead of assuming infinitely thin rays, improving the accuracy of subsurface seismic velocity model inversion. \n",
    "Here's a more detailed explanation:\n",
    "Traditional Traveltime Tomography:\n",
    "This method uses travel times of seismic waves to determine the subsurface seismic velocity distribution. It relies on the high-frequency assumption of asymptotic ray theory, which assumes wave paths are infinitely thin. \n",
    "Limitations of Traditional Method:\n",
    "This assumption leads to an ill-conditioned matrix and an unstable inversion result, meaning the calculated velocity model might not be accurate. \n",
    "Fat Ray Tomography:\n",
    "This method addresses these limitations by considering the width of the wave path, resembling the first Fresnel zone, instead of assuming infinitely thin rays. \n",
    "First Fresnel Zone:\n",
    "The first Fresnel zone is a volume around a wave path where the wave energy is concentrated. By considering this volume, fat ray tomography accounts for diffraction and other effects that are neglected in traditional ray-based tomography. \n",
    "Benefits of Fat Ray Tomography:\n",
    "Improved Accuracy: By accounting for the width of the wave path, fat ray tomography can provide a more accurate representation of the subsurface seismic velocity distribution. \n",
    "Better Resolution: The Fresnel zone provides a natural way to define the resolution of the inversion, which can lead to better resolution of the subsurface structure. \n",
    "Handles Frequency Dependence: Fat ray tomography can be adapted to account for frequency-dependent effects, which is important in near-surface applications. \n",
    "Implementation:\n",
    "Fat ray tomography involves computing the travel time fields for both forward and backward propagating waves, and then summing them to obtain the fat ray. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc10cb16",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "question = \" What is teh equation to calculate traveltime\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93214bf8-ac07-457c-812d-b4f97be9f15f",
   "metadata": {},
   "source": [
    "## Congratulations on finishing the course!\n",
    "\n",
    "To start building with the Cohere LLMs, get your API key by registering [here](https://dashboard.cohere.ai/welcome/register?utm_source=partner&utm_medium=website&utm_campaign=DeeplearningAI). \n",
    "\n",
    "Learn more about LLMs at Cohere’s [LLM.University](https://LLM.University)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
