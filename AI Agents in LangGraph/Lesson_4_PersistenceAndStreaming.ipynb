{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5789bc3-b1ae-42c7-94a8-2ef4f89946fc",
   "metadata": {},
   "source": [
    "# Lesson 4: Persistence and Streaming\n",
    "- Persistence lets you keep around the state of an agent at a particualr point in time. This can let us go back in that state and resume that state in future interaction.\n",
    "- In Streaming we can emit a list of signals about whats going on at that moment, so that for long running application we know exactly what the agent is exactly doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5762271-8736-4e94-9444-8c92bd0e8074",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "# Load appropriate envrionent variables\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "_ = load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0168aee-bce9-4d60-b827-f86a88187e31",
   "metadata": {
    "height": 115
   },
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "from langgraph.graph import StateGraph, END\n",
    "from typing import TypedDict, Annotated\n",
    "import operator\n",
    "from langchain_core.messages import AnyMessage, SystemMessage, HumanMessage, ToolMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da06a64f-a2d5-4a66-8090-9ada0930c684",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "# Create a Tavily search tool\n",
    "tool = TavilySearchResults(max_results=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2589c5b6-6cc2-4594-9a17-dccdcf676054",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "# Create the agent state\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], operator.add]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b8c102",
   "metadata": {
    "height": 30
   },
   "source": [
    "- To use persistence, checkpoints are added in langgraph. Checkpointer check states after and beteewn every node.\n",
    "- To add a persistence we use SqliteSaver. This is a simple checkpointer that uses Sqlite a builtin database under the hood and we will use inmemory database.\n",
    "- The way to use this checkpointer is that we will pass this in `graph.compile()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c033522-d2fc-41ac-8e3c-5e35872bf88d",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "\n",
    "memory = SqliteSaver.from_conn_string(\":memory:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2ba84ec-c172-4de7-ac55-e3158a531b23",
   "metadata": {
    "height": 574
   },
   "outputs": [],
   "source": [
    "# Create an agent \n",
    "\n",
    "class Agent:\n",
    "    def __init__(self, model, tools, checkpointer, system=\"\"):\n",
    "        self.system = system\n",
    "        graph = StateGraph(AgentState)\n",
    "        graph.add_node(\"llm\", self.call_openai)\n",
    "        graph.add_node(\"action\", self.take_action)\n",
    "        graph.add_conditional_edges(\"llm\", self.exists_action, {True: \"action\", False: END})\n",
    "        graph.add_edge(\"action\", \"llm\")\n",
    "        graph.set_entry_point(\"llm\")\n",
    "        # here we added the checkpointer\n",
    "        self.graph = graph.compile(checkpointer=checkpointer)\n",
    "        self.tools = {t.name: t for t in tools}\n",
    "        self.model = model.bind_tools(tools)\n",
    "\n",
    "    def call_openai(self, state: AgentState):\n",
    "        messages = state['messages']\n",
    "        if self.system:\n",
    "            messages = [SystemMessage(content=self.system)] + messages\n",
    "        message = self.model.invoke(messages)\n",
    "        return {'messages': [message]}\n",
    "\n",
    "    def exists_action(self, state: AgentState):\n",
    "        result = state['messages'][-1]\n",
    "        return len(result.tool_calls) > 0\n",
    "\n",
    "    def take_action(self, state: AgentState):\n",
    "        tool_calls = state['messages'][-1].tool_calls\n",
    "        results = []\n",
    "        for t in tool_calls:\n",
    "            print(f\"Calling: {t}\")\n",
    "            result = self.tools[t['name']].invoke(t['args'])\n",
    "            results.append(ToolMessage(tool_call_id=t['id'], name=t['name'], content=str(result)))\n",
    "        print(\"Back to the model!\")\n",
    "        return {'messages': results}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4330a7b1",
   "metadata": {
    "height": 30
   },
   "source": [
    "## Streaming messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "876d5092-b8ef-4e38-b4d7-0e80c609bf7a",
   "metadata": {
    "height": 132
   },
   "outputs": [],
   "source": [
    "prompt = \"\"\"You are a smart research assistant. Use the search engine to look up information. \\\n",
    "You are allowed to make multiple calls (either together or in sequence). \\\n",
    "Only look up information when you are sure of what you want. \\\n",
    "If you need to look up some information before asking a follow up question, you are allowed to do that!\n",
    "\"\"\"\n",
    "model = ChatOpenAI(model=\"gpt-4o\")\n",
    "abot = Agent(model, [tool], system=prompt, checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "10084a02-2928-4945-9f7c-ad3f5b33caf7",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "messages = [HumanMessage(content=\"What is the weather in sf?\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "714d1205-f8fc-4912-b148-2a45da99219c",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "thread = {\"configurable\": {\"thread_id\": \"1\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "83588e70-254f-4f83-a510-c8ae81e729b0",
   "metadata": {
    "height": 64
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_bmfLa92f6oAIKN9KvXtqbKDz', 'function': {'arguments': '{\"query\":\"current weather in San Francisco\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 22, 'prompt_tokens': 151, 'total_tokens': 173, 'prompt_tokens_details': {'cached_tokens': 0, 'audio_tokens': 0}, 'completion_tokens_details': {'reasoning_tokens': 0, 'audio_tokens': 0, 'accepted_prediction_tokens': 0, 'rejected_prediction_tokens': 0}}, 'model_name': 'gpt-4o', 'system_fingerprint': 'fp_831e067d82', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-ee83603e-d43c-49a0-9e5b-933325106839-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'current weather in San Francisco'}, 'id': 'call_bmfLa92f6oAIKN9KvXtqbKDz'}])]\n",
      "Calling: {'name': 'tavily_search_results_json', 'args': {'query': 'current weather in San Francisco'}, 'id': 'call_bmfLa92f6oAIKN9KvXtqbKDz'}\n",
      "Back to the model!\n",
      "[ToolMessage(content=\"[{'url': 'https://weatherspark.com/h/m/557/2025/3/2025%E5%B9%B43%E6%9C%88%E3%81%AE%E3%82%B5%E3%83%B3%E3%83%95%E3%83%A9%E3%83%B3%E3%82%B7%E3%82%B9%E3%82%B3%E3%80%81%E3%82%AB%E3%83%AA%E3%83%95%E3%82%A9%E3%83%AB%E3%83%8B%E3%82%A2%E5%B7%9E%E3%80%81%E3%82%A2%E3%83%A1%E3%83%AA%E3%82%AB%E5%90%88%E8%A1%86%E5%9B%BD%E3%81%AB%E3%81%8A%E3%81%91%E3%82%8B%E6%B0%97%E5%80%99%E5%B1%A5%E6%AD%B4', 'content': 'Latest Report — 5:56 PM ; Temp. 57.0°F ; Wind. 9.2 mph ; Cloud Cover. Mostly Cloudy 15,000 ft'}, {'url': 'https://www.msn.com/en-us/weather/topstories/san-francisco-bay-area-weather-march-31-2025/vi-AA1C0dfQ', 'content': 'KRON4 meteorologist John Shrable forecast the weather.'}]\", name='tavily_search_results_json', tool_call_id='call_bmfLa92f6oAIKN9KvXtqbKDz')]\n",
      "[AIMessage(content='The current weather in San Francisco is 57.0°F with mostly cloudy skies and winds at 9.2 mph.', response_metadata={'token_usage': {'completion_tokens': 27, 'prompt_tokens': 529, 'total_tokens': 556, 'prompt_tokens_details': {'cached_tokens': 0, 'audio_tokens': 0}, 'completion_tokens_details': {'reasoning_tokens': 0, 'audio_tokens': 0, 'accepted_prediction_tokens': 0, 'rejected_prediction_tokens': 0}}, 'model_name': 'gpt-4o', 'system_fingerprint': 'fp_de57b65c90', 'finish_reason': 'stop', 'logprobs': None}, id='run-6390c564-adbe-409b-8914-2d9e084321f5-0')]\n"
     ]
    }
   ],
   "source": [
    "# Call the graph with stream\n",
    "for event in abot.graph.stream({\"messages\": messages}, thread):\n",
    "    for v in event.values():\n",
    "        print(v['messages'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6cb3ef4c-58b3-401b-b104-0d51e553d982",
   "metadata": {
    "height": 98
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_kKKQnrNNnECKp5JBGtkwYqex', 'function': {'arguments': '{\"query\":\"current weather in Los Angeles\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 23, 'prompt_tokens': 567, 'total_tokens': 590, 'prompt_tokens_details': {'cached_tokens': 0, 'audio_tokens': 0}, 'completion_tokens_details': {'reasoning_tokens': 0, 'audio_tokens': 0, 'accepted_prediction_tokens': 0, 'rejected_prediction_tokens': 0}}, 'model_name': 'gpt-4o', 'system_fingerprint': 'fp_de57b65c90', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-f89ddd9e-ac62-438d-9abe-18dc3bfb2c06-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'current weather in Los Angeles'}, 'id': 'call_kKKQnrNNnECKp5JBGtkwYqex'}])]}\n",
      "Calling: {'name': 'tavily_search_results_json', 'args': {'query': 'current weather in Los Angeles'}, 'id': 'call_kKKQnrNNnECKp5JBGtkwYqex'}\n",
      "Back to the model!\n",
      "{'messages': [ToolMessage(content='[{\\'url\\': \\'https://weathershogun.com/weather/usa/ca/los-angeles/451/march/2025-03-31\\', \\'content\\': \"Los Angeles, CA - Weather Forecast Today Los Angeles, CA Home Contact Browse States Privacy Policy Terms and Conditions °F)°C) Today Tomorrow Hourly 7 days 30 days March Today | Weather | Monday, March 31, 2025 Los Angeles, California. 55° F Feels Like 54° Precipitation 48 % Wind 6 mph Humidity 86 % Today Day 64° Night 50° Precipitation 67 % Wind 7 mph UV Index (0 - 11+) 2 Los Angeles Weather Forecast Updated 27 minutes ago Last updated on March 31, 2025 12:59 AM Hourly Tomorrow 7 days 30 days Weather Forecast History Last Year\\'s Weather on This Day (March 31, 2024) Day 64° Night 52° Please note that while we strive for accuracy, the information provided may not always be correct.\"}, {\\'url\\': \\'https://www.weather2travel.com/california/los-angeles/march/\\', \\'content\\': \"Los Angeles weather in March 2025 | California, USA\\\\n\\\\n\\\\nWeather\\\\nDeals\\\\nInspiration\\\\nNews\\\\nTravel advice\\\\nHolidays\\\\nExtras\\\\nInsights\\\\n\\\\n\\\\n\\\\n\\\\nHome\\\\nNorth America\\\\nUSA\\\\nCalifornia\\\\nLos Angeles\\\\nWhere is hot in March?\\\\n\\\\nLos Angeles weather in March 2025\\\\nExpect 21°C daytime maximum temperatures in the shade with on average 9 hours of sunshine per day in Los Angeles in March. Check more long-term weather averages for Los Angeles in March before you book your next holiday to California in 2025/2026. [...] Browse the sunrise and sunset times for Los Angeles in March 2025. Select a month to view Los Angeles sunrise and sunset times for the next 12 months.\\\\nJanFebMarAprMayJunJulAugSepOctNovDec\\\\nDate\\\\nSunrise times\\\\nSunset times\\\\nSaturday, 1st March 2025\\\\n06:21\\\\n17:50\\\\nSunday, 16th March 2025\\\\n06:02\\\\n18:02\\\\nMonday, 31st March 2025\\\\n05:41\\\\n18:13\\\\nBe inspired\\\\nGet your weekly fix of holiday inspiration from some of the world\\'s best travel writers plus save on your next trip with the latest exclusive offers\"}]', name='tavily_search_results_json', tool_call_id='call_kKKQnrNNnECKp5JBGtkwYqex')]}\n",
      "{'messages': [AIMessage(content='The current weather in Los Angeles is 55°F, with a \"feels like\" temperature of 54°F. There\\'s a 48% chance of precipitation, winds at 6 mph, and humidity at 86%.', response_metadata={'token_usage': {'completion_tokens': 47, 'prompt_tokens': 1113, 'total_tokens': 1160, 'prompt_tokens_details': {'cached_tokens': 0, 'audio_tokens': 0}, 'completion_tokens_details': {'reasoning_tokens': 0, 'audio_tokens': 0, 'accepted_prediction_tokens': 0, 'rejected_prediction_tokens': 0}}, 'model_name': 'gpt-4o', 'system_fingerprint': 'fp_de57b65c90', 'finish_reason': 'stop', 'logprobs': None}, id='run-61a3f7ba-ba95-49d0-805f-a421be3e7b64-0')]}\n"
     ]
    }
   ],
   "source": [
    "# lets continue our conversation\n",
    "messages = [HumanMessage(content=\"What about in la?\")]\n",
    "# In order to be in same conversation, pass same thread ID.\n",
    "thread = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "for event in abot.graph.stream({\"messages\": messages}, thread):\n",
    "    for v in event.values():\n",
    "        print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dc3293b7-a50c-43c8-a022-8975e1e444b8",
   "metadata": {
    "height": 98
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [AIMessage(content='Los Angeles is currently warmer than San Francisco. Los Angeles has a temperature of 55°F, while San Francisco has a temperature of 57°F. However, the \"feels like\" temperature in Los Angeles is 54°F, which is a bit lower.', response_metadata={'token_usage': {'completion_tokens': 55, 'prompt_tokens': 1171, 'total_tokens': 1226, 'prompt_tokens_details': {'cached_tokens': 1152, 'audio_tokens': 0}, 'completion_tokens_details': {'reasoning_tokens': 0, 'audio_tokens': 0, 'accepted_prediction_tokens': 0, 'rejected_prediction_tokens': 0}}, 'model_name': 'gpt-4o', 'system_fingerprint': 'fp_de57b65c90', 'finish_reason': 'stop', 'logprobs': None}, id='run-bb6dbf4f-9616-42e5-b433-29d010642b9d-0')]}\n"
     ]
    }
   ],
   "source": [
    "messages = [HumanMessage(content=\"Which one is warmer?\")]\n",
    "thread = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "for event in abot.graph.stream({\"messages\": messages}, thread):\n",
    "    for v in event.values():\n",
    "        print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0722c3d4-4cbf-43bf-81b0-50f634c4ce61",
   "metadata": {
    "height": 98
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [AIMessage(content=\"It seems that your question is missing some context. Could you please provide more details about what you're comparing? For example, are you asking about the weather in two different locations, the warmth of different types of clothing, or something else? Let me know so I can assist you better.\", response_metadata={'token_usage': {'completion_tokens': 59, 'prompt_tokens': 203, 'total_tokens': 262, 'prompt_tokens_details': {'cached_tokens': 0, 'audio_tokens': 0}, 'completion_tokens_details': {'reasoning_tokens': 0, 'audio_tokens': 0, 'accepted_prediction_tokens': 0, 'rejected_prediction_tokens': 0}}, 'model_name': 'gpt-4o', 'system_fingerprint': 'fp_f9f4fb6dbf', 'finish_reason': 'stop', 'logprobs': None}, id='run-3f0bc8d6-620f-4893-966d-c0851a021603-0')]}\n"
     ]
    }
   ],
   "source": [
    "messages = [HumanMessage(content=\"Which one is warmer?\")]\n",
    "# If qwe change the thread ID , langague model get confused\n",
    "thread = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "for event in abot.graph.stream({\"messages\": messages}, thread):\n",
    "    for v in event.values():\n",
    "        print(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace59a36-3941-459e-b9d1-ac5a4a1ed3ae",
   "metadata": {},
   "source": [
    "## Streaming tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6b2f82fe-3ec4-4917-be51-9fb10d1317fa",
   "metadata": {
    "height": 81
   },
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.aiosqlite import AsyncSqliteSaver\n",
    "\n",
    "memory = AsyncSqliteSaver.from_conn_string(\":memory:\")\n",
    "abot = Agent(model, [tool], system=prompt, checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ee0fe1c7-77e2-499c-a2f9-1f739bb6ddf0",
   "metadata": {
    "height": 200
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/langchain_core/_api/beta_decorator.py:87: LangChainBetaWarning: This API is in beta and may change in the future.\n",
      "  warn_beta(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling: {'name': 'tavily_search_results_json', 'args': {'query': 'current weather in San Francisco'}, 'id': 'call_Q7Ja7dXreNf611ip7uPszCbI'}\n",
      "Back to the model!\n",
      "The| current| weather| in| San| Francisco| is| mostly| cloudy| with| a| temperature| of| |57|.|0|°F| and| wind| speed| of| |9|.|2| mph|.|"
     ]
    }
   ],
   "source": [
    "messages = [HumanMessage(content=\"What is the weather in SF?\")]\n",
    "thread = {\"configurable\": {\"thread_id\": \"4\"}}\n",
    "async for event in abot.graph.astream_events({\"messages\": messages}, thread, version=\"v1\"):\n",
    "    kind = event[\"event\"]\n",
    "    if kind == \"on_chat_model_stream\":\n",
    "        content = event[\"data\"][\"chunk\"].content\n",
    "        if content:\n",
    "            # Empty content in the context of OpenAI means\n",
    "            # that the model is asking for a tool to be invoked.\n",
    "            # So we only print non-empty content\n",
    "            print(content, end=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f303b1-a4d0-408c-8cc0-515ff980717f",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
