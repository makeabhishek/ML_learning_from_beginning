{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3fbb2ea-c80c-49f3-ba3c-91ed0271fe6c",
   "metadata": {},
   "source": [
    "# LangChain Chat with Your Data\n",
    "\n",
    "LLM's like chatGPT can answer the questions on the lot of topics. But an LLM on isolation only knows what it is trained on, whcih doesn't include your persoal data. \n",
    "\n",
    "So we want to use our own documents to do conversation using langchain. \n",
    "\n",
    "We will see \n",
    "1. how to use langchain document loaders\n",
    "2. How to split these docuemtns scemantially into meaningful chunks.\n",
    "3. Overview of scemantic search. Basic idea of fetching information from docuemnt\n",
    "4. How to use retrieve docuemnts to eanble an LLM to answer questions about the document\n",
    "5. Memory: how to build fully funcitonal chatbot.\n",
    "\n",
    "\n",
    "## Retrieval augmented generation\n",
    " \n",
    "In retrieval augmented generation (RAG), an LLM retrieves contextual documents from an external dataset as part of its execution. \n",
    "\n",
    "This is useful if we want to ask question about specific documents (e.g., our PDFs, a set of videos, etc). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5cf75c4-b54a-4c90-8130-4242f2fe229a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
