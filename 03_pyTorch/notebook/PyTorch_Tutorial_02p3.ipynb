{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76bd3987-6c64-4950-a0a3-ce0a042bbd8e",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center; font-size: 32px; font-weight: bold;\">\n",
    "    PyTorch Tutorial 02 - Basic Matrix Algebra\n",
    "</div>\n",
    "\n",
    "## Matrix Operations:  Determinant & Inverse\n",
    "\n",
    "### (1) Matrix Multiplication\n",
    "In PyTorch, you can perform matrix multiplication using `torch.mm()`, `torch.matmul()`, and the `@` operator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8812da-b8de-493a-b76f-32c84f13ef70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrix Multiplication\n",
    "\n",
    "# Define two matrices\n",
    "A = torch.tensor([[1, 2], [3, 4]])\n",
    "B = torch.tensor([[5, 6], [7, 8]])\n",
    "\n",
    "# Using torch.mm() (Only for 2D Matrices)\n",
    "result = torch.mm(A, B)\n",
    "\n",
    "print(result)\n",
    "\n",
    "# Using torch.matmul() (Generalized)\n",
    "result = torch.matmul(A, B)\n",
    "print(result)\n",
    "\n",
    "# Using @ Operator (Shorthand for matmul)\n",
    "result = A @ B\n",
    "print(result)\n",
    "\n",
    "# Matrix Multiplication for Higher Dimensions\n",
    "A = torch.randn(2, 3, 4)  # Batch of 2 matrices of size (3x4)\n",
    "B = torch.randn(2, 4, 5)  # Batch of 2 matrices of size (4x5)\n",
    "\n",
    "result = torch.matmul(A, B)  # Resulting shape will be (2, 3, 5)\n",
    "print(result.shape)  # Output: torch.Size([2, 3, 5])\n",
    "\n",
    "# Element-wise Multiplication (* Operator). NOTE: Make sure A and B have the same shape! Otherwise, PyTorch will try to broadcast them\n",
    "result = A * B  # Element-wise multiplication (Hadamard Product)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64752e98-ef5f-450b-8ebd-13fecd705a43",
   "metadata": {},
   "source": [
    "### Check square Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e632eb4b-7b81-4945-ae9b-04cb2adca97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a square matrix\n",
    "A = torch.tensor([[4., 7.], [2., 6.]])\n",
    "\n",
    "# Example 1: Square Matrix\n",
    "B= torch.tensor([[1, 2, 3], \n",
    "                  [4, 5, 6], \n",
    "                  [7, 8, 9]])\n",
    "\n",
    "# Example 2: Non-Square Matrix\n",
    "C = torch.tensor([[1, 2, 3], \n",
    "                  [4, 5, 6]])\n",
    "\n",
    "# Let's first check if a Matrix is Square\n",
    "def check_square_matrix(matrix):\n",
    "    rows, cols = matrix.shape  # Get matrix dimensions\n",
    "    if rows == cols:\n",
    "        print(f\" The matrix is square with dimensions: ({rows}, {cols})\")\n",
    "    else:\n",
    "        print(f\" The matrix is NOT square! Dimensions: ({rows}, {cols})\")\n",
    "\n",
    "# Run the function\n",
    "check_square_matrix(A)  # Should print: Square\n",
    "check_square_matrix(B)  # Should print: Square\n",
    "check_square_matrix(C)  # Should print: NOT Square"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc38c25c-8856-4106-9e7c-2122b0a8db7e",
   "metadata": {},
   "source": [
    "### (2) Matrix Operations in PyTorch\n",
    "\n",
    "| **Operation** | **PyTorch Function** |\n",
    "|--------------|----------------------|\n",
    "| **Determinant** | `torch.det(A)` |\n",
    "| **Inverse** | `torch.inverse(A)` |\n",
    "| **Transpose** | `A.T` or `torch.transpose(A, 0, 1)` |\n",
    "| **Trace (Sum of Diagonal Elements)** | `torch.trace(A)`|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7c5f9b-1e66-41c4-9f85-9d02df0766b5",
   "metadata": {},
   "source": [
    "### Compute the Determinant\n",
    "The determinant is useful for checking if a matrix is invertible (if det(A) ≠ 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72061592-1c9d-4a1d-9bcf-c2fdddb667fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a square matrix\n",
    "A = torch.tensor([[4., 7.], \n",
    "                  [2., 6.]])\n",
    "\n",
    "# Compute determinant of a square matrix\n",
    "det_A = torch.det(A)\n",
    "print(\"Determinant of A:\", det_A.item())  # .item() extracts the scalar value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e2b8ab-a011-4bd6-86a9-bd502253d085",
   "metadata": {},
   "source": [
    "### Inverse of matrix\n",
    "The inverse exists only if $det(A) \\neq 0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba2b760-31e5-4d0c-8be6-3de466cb83e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the inverse\n",
    "inv_A = torch.inverse(A)\n",
    "print(\"Inverse of A:\\n\", inv_A)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19cc5ffc-d372-45f7-bbea-e1162a353504",
   "metadata": {},
   "source": [
    "### Transpose of a Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c88f358-1442-4f96-b637-7ed3da8b82f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "A_T = A.T  # or torch.transpose(A, 0, 1)\n",
    "print(\"Transpose of A:\\n\", A_T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a35b800-e301-4ce2-9e86-911d6c292438",
   "metadata": {},
   "source": [
    "### Trace of a Matrix (Sum of Diagonal Elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf30663-0725-4376-9c72-a3614ea6b444",
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_A = torch.trace(A)\n",
    "print(\"Trace of A:\", trace_A.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cdad4fd-b874-4f0f-8ff0-2dc16b0aab94",
   "metadata": {},
   "source": [
    "### (3) Common Matrix Operations for Scientific Research in PyTorch\n",
    "\n",
    "| **Operation** | **PyTorch Function** | **Use Case** |\n",
    "|--------------|----------------------|-------------|\n",
    "| **Norms** | `torch.norm(A, p)` | Regularization, Optimization |\n",
    "| **Eigenvalues & Eigenvectors** | `torch.linalg.eig(A)` | PCA, Stability Analysis |\n",
    "| **Singular Value Decomposition (SVD)** | `torch.svd(A)` | Dimensionality Reduction |\n",
    "| **Rank** | `torch.linalg.matrix_rank(A)` | Feature Selection, Linear Dependence |\n",
    "| **Condition Number** | `torch.linalg.cond(A)` | Numerical Stability |\n",
    "| **Pseudo Inverse** | `torch.linalg.pinv(A)` | Least Squares Solutions |\n",
    "| **Solving Linear Equations** | `torch.linalg.solve(A, b)` | Scientific Simulations |\n",
    "| **Cholesky Decomposition** | `torch.linalg.cholesky(A)` | Monte Carlo Simulations |\n",
    "| **QR Decomposition** | `torch.linalg.qr(A)` | Orthogonalization |\n",
    "\n",
    "**These matrix operations are essential for research in AI, Physics, and Engineering!**\n",
    "\n",
    "Why These Operations Matter?\n",
    "- __Machine Learning__: SVD, Eigenvalues (PCA), Norms (Regularization)\n",
    "- __Physics & Engineering__: Determinants (Solving Equations), Cholesky, QR Decomposition\n",
    "- __Data Science__: Rank (Feature Selection), Pseudo Inverse (Ill-posed Problems)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07441a4d-4923-43c1-93ba-532059590821",
   "metadata": {},
   "source": [
    "### Matrix Norms (Measure of Matrix Size)\n",
    "Matrix norms are used to measure the size of a matrix, commonly used in optimization and numerical analysis. \\\n",
    "Used in: Machine Learning, Regularization, Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b915eb6a-7db0-4a98-8256-e1f0f43f20c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = torch.tensor([[3., 4.], \n",
    "                  [5., 6.]])\n",
    "\n",
    "# Frobenius Norm\n",
    "frobenius_norm = torch.norm(A)\n",
    "print(\"Frobenius Norm:\", frobenius_norm.item())\n",
    "\n",
    "# L1 Norm (Sum of absolute values)\n",
    "l1_norm = torch.norm(A, p=1)\n",
    "print(\"L1 Norm:\", l1_norm.item())\n",
    "\n",
    "# L∞ Norm (Maximum absolute row sum)\n",
    "linf_norm = torch.norm(A, p=float('inf'))\n",
    "print(\"L∞ Norm:\", linf_norm.item())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1427a7d-ca9b-4f9d-9fc5-22ef65ff8820",
   "metadata": {},
   "source": [
    "### Eigenvalues & Eigenvectors (Spectral Analysis)\n",
    "Eigenvalues and eigenvectors help understand transformations applied by matrices (important in PCA, Graph Theory, Quantum Mechanics). \\\n",
    "Used in: Principal Component Analysis (PCA), Stability Analysis, Quantum Mechanics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6375d2-4166-41af-ba37-615276e2aeff",
   "metadata": {},
   "outputs": [],
   "source": [
    "eigenvalues, eigenvectors = torch.linalg.eig(A)\n",
    "print(\"Eigenvalues:\\n\", eigenvalues)\n",
    "print(\"Eigenvectors:\\n\", eigenvectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf4e738f-b740-4855-bf9d-2346b022b7df",
   "metadata": {},
   "source": [
    "### Singular Value Decomposition (SVD)\n",
    "SVD decomposes a matrix into three components and is useful for dimensionality reduction and signal processing. \\\n",
    "Used in: PCA, Image Compression, Signal Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46c4639-af30-4534-a86a-3e73ca7e531d",
   "metadata": {},
   "outputs": [],
   "source": [
    "U, S, V = torch.svd(A)\n",
    "print(\"U:\\n\", U)\n",
    "print(\"Singular Values:\\n\", S)\n",
    "print(\"V:\\n\", V)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e6cd34-d6ec-4ab9-bdc4-04d9cf714422",
   "metadata": {},
   "source": [
    "### Rank of a Matrix (Linearly Independent Rows/Columns)\n",
    "The rank of a matrix tells how many linearly independent rows or columns exist.\n",
    "\n",
    "Used in: Linear Systems, Data Compression, Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab330cd-9c5a-49f8-9596-271a80d112ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_A = torch.linalg.matrix_rank(A)\n",
    "print(\"Rank of A:\", rank_A.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52b5ea8-c351-441a-9fe1-507a3a277b0d",
   "metadata": {},
   "source": [
    "### Condition Number (Numerical Stability)\n",
    "The condition number of a matrix helps determine if a system is well-conditioned (low condition number) or ill-conditioned (high condition number). \\\n",
    "Used in: Solving Linear Systems, Stability Analysis, Inverse Problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c5f062-593d-4bd2-aa84-6d2f5086de18",
   "metadata": {},
   "outputs": [],
   "source": [
    "cond_A = torch.linalg.cond(A)\n",
    "print(\"Condition Number of A:\", cond_A.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5609780d-922b-4687-94a6-212598ca65de",
   "metadata": {},
   "source": [
    "### Moore-Penrose Pseudo Inverse (For Non-Invertible Matrices) \\ Least Squares Solutions\n",
    "Some matrices are not invertible (singular). The Moore-Penrose pseudo-inverse helps find a solution even when an inverse doesn't exist. \\\n",
    "Used in: Least Squares Solutions, Machine Learning Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdef5fbc-69bb-402c-beec-772b87f087ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudo_inv_A = torch.linalg.pinv(A)\n",
    "print(\"Moore-Penrose Pseudo-Inverse of A:\\n\", pseudo_inv_A)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee4b83ae-0aad-47d0-9280-10ff181ee451",
   "metadata": {},
   "source": [
    "### Solving Linear Systems $(Ax = b)$\n",
    "If you have a system of equations $Ax = b$, you can solve for $x$. \\\n",
    "Used in: Engineering Simulations, Optimization Problems, Scientific Computing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d01715f-bbac-449a-b20e-485586c39694",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = torch.tensor([10., 8.])  # Right-hand side of the equation Ax = b\n",
    "x = torch.linalg.solve(A, b)\n",
    "print(\"Solution x:\\n\", x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f8d483-8573-4e72-bf24-e4e86bc32387",
   "metadata": {},
   "source": [
    "### Cholesky Decomposition (For Positive Definite Matrices)\n",
    "A matrix decomposition used in solving linear systems efficiently. \\\n",
    "Used in: Monte Carlo Simulations, Gaussian Processes, Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b20c22-4103-4515-a68b-85d7ca532ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cholesky_A = torch.linalg.cholesky(A @ A.T)  # A*A^T makes it positive definite\n",
    "print(\"Cholesky Decomposition:\\n\", cholesky_A)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e299ea5-02e8-46a8-baf5-e72d253ab180",
   "metadata": {},
   "source": [
    "### QR Decomposition (Orthogonalization)\n",
    "QR Decomposition is used to factorize a matrix into an orthogonal matrix (Q) and an upper triangular matrix (R). \\\n",
    "Used in: Least Squares Regression, Gram-Schmidt Orthogonalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31b36f3-95aa-4562-bff3-42d4aa2d8c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# QR Decomposition (Orthogonalization): QR Decomposition is used to factorize a matrix into an orthogonal matrix (Q) and an upper triangular matrix (R).\n",
    "Q, R = torch.linalg.qr(A)\n",
    "print(\"Q Matrix:\\n\", Q)\n",
    "print(\"R Matrix:\\n\", R)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4062b72-f760-49a4-aef7-f7f569d9c8b1",
   "metadata": {},
   "source": [
    "### More Matrix Operations in PyTorch\n",
    "\n",
    "| **Operation** | **PyTorch Function** | **Use Case** |\n",
    "|--------------|----------------------|-------------|\n",
    "| **Hadamard Product (Element-wise Multiplication)** | `A * B` | Neural Networks |\n",
    "| **Kronecker Product** | `torch.kron(A, B)` | Quantum Computing |\n",
    "| **Outer Product** | `torch.ger(v1, v2)` | Feature Expansion |\n",
    "| **Cross Product** | `torch.cross(v1, v2)` | Physics, Graphics |\n",
    "| **Batch Determinants** | `torch.linalg.det(batch_A)` | ML Batch Processing |\n",
    "| **Log-Determinant** | `torch.logdet(A)` | Gaussian Distributions |\n",
    "| **Matrix Exponential** | `torch.linalg.matrix_exp(A)` | Differential Equations |\n",
    "| **Matrix Power** | `torch.linalg.matrix_power(A, n)` | Graph Theory |\n",
    "| **Diagonal Extraction** | `torch.diag(A)` | Matrix Factorizations |\n",
    "| **Anti-Diagonal Extraction** | `torch.diag(torch.fliplr(A))` | Signal Processing |\n",
    "| **Toeplitz Matrix** | `scipy.linalg.toeplitz()` | Time Series Analysis |\n",
    "\n",
    "🚀 **These matrix operations are used in AI, Quantum Computing, and Scientific Simulations!**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6090dd4-3581-49f3-a7bf-1792757834a7",
   "metadata": {},
   "source": [
    "### Hadamard Product (Element-wise Multiplication)\n",
    "Unlike standard matrix multiplication, this is a simple element-wise product.\n",
    "Used in: Neural Networks (Weight Updates), Signal Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0546ca1f-0808-45b3-af20-cbd750db0cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = torch.tensor([[1, 2], [3, 4]])\n",
    "B = torch.tensor([[5, 6], [7, 8]])\n",
    "\n",
    "hadamard_product = A * B  # Element-wise multiplication\n",
    "print(hadamard_product)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ff7a55-3c16-4a80-9b6f-5825404780df",
   "metadata": {},
   "source": [
    "### Kronecker Product (Tensor Product of Two Matrices)\n",
    "The Kronecker Product (denoted as $𝐴⊗𝐵$) is a special matrix operation that expands two matrices into a larger block matrix. \\\n",
    "Kronecker Product creates a larger block matrix from two matrices. \\\n",
    "Given two matrices: A and B, Each entry in A is multiplied by the entire matrix B. \\\n",
    "Used in: \n",
    "- Quantum Computing: Describes tensor product states in quantum mechanics.\n",
    "- Graph Theory: Used in graph adjacency matrices.\n",
    "- Signal Processing: Expands matrices for multi-dimensional systems.\n",
    "- Machine Learning: Feature interactions in tensor networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39669c7-18e6-41b5-8b2c-32f1b691245a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define matrices A and B\n",
    "A = torch.tensor([[1, 2], [3, 4]])\n",
    "B = torch.tensor([[0, 5], [6, 7]])\n",
    "\n",
    "# Compute Kronecker Product\n",
    "kronecker_product = torch.kron(A, B)\n",
    "print(kronecker_product)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3737a590-ad06-4e46-93b9-c7dfe27f1d86",
   "metadata": {},
   "source": [
    "### Outer Product\n",
    "Creates a larger matrix from two vectors. \\\n",
    "Used in: Feature Expansion, Higher-Order Tensor Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266fdfea-eccc-4fec-a583-971470c5dd1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = torch.tensor([1, 2, 3])\n",
    "v2 = torch.tensor([4, 5, 6])\n",
    "\n",
    "outer_product = torch.ger(v1, v2)\n",
    "print(outer_product)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f56a07-7d2f-4716-8511-9ea9edbedb72",
   "metadata": {},
   "source": [
    "### Cross Product (3D Vectors Only)\n",
    "Used in: Physics, Computer Graphics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6c97d4-73ba-47bb-acc0-980b6103b652",
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = torch.tensor([1., 2., 3.])\n",
    "v2 = torch.tensor([4., 5., 6.])\n",
    "\n",
    "cross_product = torch.cross(v1, v2)\n",
    "print(cross_product)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fdcfa15-5f05-4167-8caf-63f80836bf81",
   "metadata": {},
   "source": [
    "### Determinant of a Batch of Matrices\n",
    "If you have multiple matrices, you can compute their determinant in batch mode. \\\n",
    "Used in: Neural Networks (Batch Processing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2a9913-e3ef-43b8-a0ee-64dad1c88b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_A = torch.rand(5, 3, 3)  # 5 Matrices of 3x3\n",
    "determinants = torch.linalg.det(batch_A)\n",
    "print(determinants)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891a45b5-6e84-42a7-aad8-19b111844c3a",
   "metadata": {},
   "source": [
    "### Log-Determinant (More Stable than `det()`)\n",
    "To avoid numerical underflow/overflow, use `logdet()`. \\\n",
    "Used in: Machine Learning (Gaussian Distributions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af446f7-66bf-4592-8385-8cac77e76db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_det = torch.logdet(A.float())  # Must use floating-point tensor\n",
    "print(log_det)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce08dee-2fd9-4af9-bc29-2fcbecc1cd57",
   "metadata": {},
   "source": [
    "### Matrix Exponential\n",
    "Computes $e^A$ (useful for differential equations). \\\n",
    "Used in: Dynamical Systems, Control Theory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dbc8a3a-2f58-4234-a252-b8122fd8dba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_A = torch.linalg.matrix_exp(A.float())\n",
    "print(exp_A)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbba20d0-434e-47ba-8053-f6ce261d8a89",
   "metadata": {},
   "source": [
    "### Matrix Power\n",
    "Compute $A^n$ for a square matrix. \\\n",
    "Used in: Graph Theory (Adjacency Matrices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91e6b2e-2f50-4d3c-9820-09afebdbb8a8",
   "metadata": {},
   "source": [
    "### Diagonal and Anti-Diagonal Extraction\n",
    "Extracts diagonal or anti-diagonal elements. \\\n",
    "Used in: Matrix Factorizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63097d61-054e-4840-9928-3ce60d8229cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "diagonal_elements = torch.diag(A)\n",
    "print(\"Diagonal:\", diagonal_elements)\n",
    "\n",
    "# Reverse columns, then extract diagonal\n",
    "anti_diagonal_elements = torch.diag(torch.fliplr(A))\n",
    "print(\"Anti-Diagonal:\", anti_diagonal_elements)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81e1f87-5097-4dd0-b0dc-8307e5025836",
   "metadata": {},
   "source": [
    "### Toeplitz and Circulant Matrices\n",
    "Toeplitz matrices have constant diagonals, often used in signal processing.\\\n",
    "Used in: Time Series Analysis, Image Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda733a6-f132-4967-92fe-bf2b4ef866d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.linalg import toeplitz\n",
    "import torch\n",
    "\n",
    "first_col = torch.tensor([1, 2, 3, 4])\n",
    "toeplitz_matrix = torch.tensor(toeplitz(first_col, first_col))\n",
    "print(toeplitz_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d037a1-d5b6-4065-bc0b-2f1f34f1e0a6",
   "metadata": {},
   "source": [
    "## <span style=\"color: yellow;\">Next : Advanced Matrix Operations in PyTorch</span>\n",
    "Helpful for scientific research, deep learning, or AI \\\n",
    "- Tensor Factorizations (CP Decomposition, Tucker Decomposition)\n",
    "- Graph-based Matrix Operations\n",
    "- Sparse Matrix Computations (PyTorch supports sparse tensors)\n",
    "\n",
    "## Advanced Matrix Operations in PyTorch\n",
    "\n",
    "| **Operation** | **PyTorch Function** | **Use Case** |\n",
    "|--------------|----------------------|-------------|\n",
    "| **CP Decomposition** | `parafac()` | Tensor Factorization |\n",
    "| **Tucker Decomposition** | `tucker()` | Dimensionality Reduction |\n",
    "| **Sparse Matrix Representation** | `tensor.to_sparse()` | GNNs, Large Data |\n",
    "| **Sparse Matrix Multiplication** | `torch.sparse.mm()` | High-Speed Computation |\n",
    "| **Adjacency Matrix** | `torch.tensor([[..]])` | Graph Theory |\n",
    "| **Degree Matrix** | `torch.diag(adj_matrix.sum(dim=1))` | Node Connectivity |\n",
    "| **Graph Laplacian** | `degree_matrix - adj_matrix` | Graph Signal Processing |\n",
    "| **PageRank Transition Matrix** | `torch.linalg.inv(D) @ A` | Google’s Algorithm |\n",
    "\n",
    "**These operations are essential in AI, Data Science, and Graph Analytics!**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def29593-ae4d-4c51-86a6-a8430f90b5b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
