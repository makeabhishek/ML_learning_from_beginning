{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf81c5e6-fa4e-4df8-a836-37059d176c96",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center; font-size: 32px; font-weight: bold;\">\n",
    "    Logistic Regression\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9fed23-2ff2-4573-b1ac-4e8a8a09fbd4",
   "metadata": {},
   "source": [
    "## **Logistic Regression: A Classification Algorithm**\n",
    "Logistic Regression is a **supervised learning algorithm** used for **classification tasks**. Despite its name, it is **not a regression algorithm** but rather a method for predicting **categorical outcomes** (e.g., \"yes\" or \"no\", \"spam\" or \"not spam\", etc.).\n",
    "\n",
    "---\n",
    "\n",
    "### **How Logistic Regression Works**\n",
    "Logistic Regression works by applying the **sigmoid (logistic) function** to a **linear equation**. This converts continuous values into probabilities between **0 and 1**.\n",
    "\n",
    "#### **Mathematical Representation**\n",
    "1. **Linear Combination of Features**  \n",
    "   Given input features \\(X\\), the model computes a weighted sum:\n",
    "\n",
    "   $$\n",
    "   z = W X + b\n",
    "   $$\n",
    "\n",
    "   Where:\n",
    "   - \\(X\\) = input features\n",
    "   - \\(W\\) = weights (learned during training)\n",
    "   - \\(b\\) = bias term\n",
    "\n",
    "2. **Applying the Sigmoid Function**  \n",
    "   The output \\(z\\) is passed through the **sigmoid function**:\n",
    "\n",
    "   $$\n",
    "   \\sigma(z) = \\frac{1}{1 + e^{-z}}\n",
    "   $$\n",
    "\n",
    "   This ensures the output is a probability between 0 and 1.\n",
    "\n",
    "3. **Decision Rule**  \n",
    "   - If \\( \\sigma(z) > 0.5 \\), classify as **1** (positive class).\n",
    "   - If \\( \\sigma(z) \\leq 0.5 \\), classify as **0** (negative class).\n",
    "\n",
    "---\n",
    "\n",
    "### **Types of Logistic Regression**\n",
    "1. **Binary Logistic Regression**  \n",
    "   - Used when there are **two** classes (e.g., spam or not spam).\n",
    "   - Example: Predicting if an email is **spam (1) or not spam (0)**.\n",
    "\n",
    "2. **Multiclass Logistic Regression (Softmax Regression)**  \n",
    "   - Used when there are **more than two** classes.\n",
    "   - Uses the **softmax function** instead of the sigmoid function.\n",
    "   - Example: Predicting if an image contains a **cat (class 0), dog (class 1), or bird (class 2)**.\n",
    "\n",
    "---\n",
    "\n",
    "### **Loss Function: Binary Cross-Entropy**\n",
    "To measure how well the model is performing, we use the **Binary Cross-Entropy (Log Loss)**:\n",
    "\n",
    "$$\n",
    "Loss = -\\frac{1}{m} \\sum_{i=1}^{m} \\left[ y_i \\log(\\hat{y_i}) + (1 - y_i) \\log(1 - \\hat{y_i}) \\right]\n",
    "$$\n",
    "\n",
    "where:\n",
    "- \\( y_i \\) = actual label (0 or 1)\n",
    "- \\( \\hat{y_i} \\) = predicted probability\n",
    "- \\( m \\) = number of samples\n",
    "\n",
    "This function **penalizes incorrect predictions more heavily** when the model is confident but wrong.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "### **Example: Logistic Regression in Python**\n",
    "Using **scikit-learn** to classify whether a tumor is malignant (1) or benign (0):\n",
    "\n",
    "```\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Generate synthetic classification data\n",
    "X, y = make_classification(n_samples=1000, n_features=5, random_state=42)\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train Logistic Regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb99f05-ad0f-4160-a9ff-e6b47673fc94",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
