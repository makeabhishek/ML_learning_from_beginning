{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf81c5e6-fa4e-4df8-a836-37059d176c96",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center; font-size: 32px; font-weight: bold;\">\n",
    "    Gradient Descent with Autograd and Backpropagation\n",
    "</div>\n",
    "\n",
    "<center><img src='./images/CG_addition.PNG' width=350px></center> \n",
    "Example: optimize the model for linear regression\n",
    "\n",
    "1. Manual\n",
    "- Prediction: <span style=\"color: Green;\">Manually</span>\n",
    "- Gradients Computation: <span style=\"color: Green;\">Manually</span>\n",
    "- Los Computation: <span style=\"color: Green;\">Manually</span>\n",
    "- Parameter Updates: <span style=\"color: Green;\">Manually</span>\n",
    "\n",
    "2. Using Autograd\n",
    "- Prediction: <span style=\"color: Green;\">Manually</span>\n",
    "- Gradients Computation: <span style=\"color: Red;\">Autograd</span>\n",
    "- Los Computation: <span style=\"color: Green;\">Manually</span>\n",
    "- Parameter Updates: <span style=\"color: Green;\">Manually</span>\n",
    "\n",
    "3. Using pytorch loss and optimizer\n",
    "- Prediction: <span style=\"color: Green;\">Manually</span>\n",
    "- Gradients Computation: <span style=\"color: Red;\">Autograd</span>\n",
    "- Los Computation: <span style=\"color: Red;\">PyTorch Loss</span>\n",
    "- Parameter Updates: <span style=\"color: Red;\">PyTorch Optimizer</span>\n",
    "\n",
    "4. Using everything from pytorch\n",
    "- Prediction: <span style=\"color: Red;\">PyTorch Model</span>\n",
    "- Gradients Computation: <span style=\"color: Red;\">Autograd</span>\n",
    "- Los Computation: <span style=\"color: Red;\">PyTorch Loss</span>\n",
    "- Parameter Updates: <span style=\"color: Red;\">PyTorch Optimizer</span>\n",
    "\n",
    "## <span style=\"color: yellow;\">Prerequisites: gradient descent and linear regression</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d565f832-f3df-41e1-9f97-d1930f926c04",
   "metadata": {},
   "source": [
    "## **Linear Regression:**\n",
    "Linear Regression is a fundamental **supervised learning algorithm** used for **predicting continuous values**. It models the relationship between **independent variables (features)** and a **dependent variable (target/output)** by fitting a straight line.\n",
    "\n",
    "---\n",
    "\n",
    "## **1. How Linear Regression Works**\n",
    "Linear Regression assumes a **linear relationship** between input features $(X)$ and the target variable $(y)$. \\\n",
    "The equation for **Simple Linear Regression** (one feature) is:\n",
    "$$\n",
    "y = W X + b\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $(X)$ = Input feature (independent variable)\n",
    "- $(y)$ = Output prediction (dependent variable)\n",
    "- $(W)$ = Weight (slope of the line)\n",
    "- $(b)$ = Bias (intercept or shift on y-axis)\n",
    "\n",
    "For **Multiple Linear Regression** (more than one feature):\n",
    "$$\n",
    "y = W_1 X_1 + W_2 X_2 + \\dots + W_n X_n + b\n",
    "$$\n",
    "in matrix notation:\n",
    "\n",
    "$$\n",
    "Y = X W + b\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $(X)$ is the feature matrix (shape: $(m \\times n)$, where $(m)$ is the number of samples, and $(n)$ is the number of features).\n",
    "- $(W)$ is the weight vector.\n",
    "- $(b)$ is the bias term.\n",
    "\n",
    "---\n",
    "\n",
    "### **2. Loss Function: Mean Squared Error (MSE)**\n",
    "To measure the accuracy of the model, we use the **Mean Squared Error (MSE) loss function**, which calculates the average squared differences between predicted and actual values:\n",
    "\n",
    "$$\n",
    "MSE = \\frac{1}{m} \\sum_{i=1}^{m} (y_i - \\hat{y_i})^2\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $(y_i)$ is the actual value.\n",
    "- $(\\hat{y_i})$ is the predicted value.\n",
    "- $(m)$ is the number of samples.\n",
    "\n",
    "Our goal is to minimize this error.\n",
    "\n",
    "---\n",
    "\n",
    "### **3. Optimizing Linear Regression: Gradient Descent**\n",
    "To find the optimal weights $(W)$ and bias $(b)$, we use **Gradient Descent**, an optimization algorithm that updates weights iteratively:\n",
    "\n",
    "$$\n",
    "W := W - \\alpha \\frac{\\partial (MSE)}{\\partial W}\n",
    "$$\n",
    "\n",
    "$$\n",
    "b := b - \\alpha \\frac{\\partial (MSE)}{\\partial b}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $\\alpha$ (learning rate) controls the step size of updates.\n",
    "- The partial derivatives or gradeient compute how much to adjust $W$ and $b$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882ddc60-3bf3-4498-9b99-98df665a6e64",
   "metadata": {},
   "source": [
    "### Notation and Convention in Machine Learning (ML)\n",
    "- Many machine learning algorithms (e.g., linear regression, logistic regression, neural networks) rely on **linear algebra**, where matrices are denoted by capital letters ($(X)$) and vectors  are denoted by small letter ($(X)$).\n",
    "- In ML, the notation for Training Data ($(X)$) and for Labels ($(X)$) is a convention derived from statistics and linear algebra.\n",
    "\n",
    "#### **1. Training Data/ input features: $(X)$ (Capital Letter)**\n",
    "- The training data  is typically represented as a **matrix** (2D array), where each row corresponds to a data sample, and each column corresponds to a feature.\n",
    "- Matrices are usually denoted by **uppercase letters** in mathematical notation, which is why **$(X)$ is used for the feature matrix**.\n",
    "\n",
    "#### **2. Target / Labels:  $(y)$ (Lowercase Letter)**\n",
    "- The labels or target values are often represented as a **vector** (1D array), where each element corresponds to the output associated with a row in $(X)$.\n",
    "- Vectors are conventionally represented using **lowercase letters**, which is why **$(y)$ is used for the target variable**.\n",
    "\n",
    "#### **Example**\n",
    "If we have a dataset with $(m)$ training examples and $(n)$ features:\n",
    "\n",
    "$$\n",
    "X =\n",
    "\\begin{bmatrix}\n",
    "x_{1,1} & x_{1,2} & \\dots & x_{1,n} \\\\\n",
    "x_{2,1} & x_{2,2} & \\dots & x_{2,n} \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "x_{m,1} & x_{m,2} & \\dots & x_{m,n}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "where each row represents a sample, and each column represents a feature.\n",
    "\n",
    "And the target labels:\n",
    "$$\n",
    "y =\n",
    "\\begin{bmatrix}\n",
    "y_1 \\\\\n",
    "y_2 \\\\\n",
    "\\vdots \\\\\n",
    "y_m\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "where each $(y_i)$ corresponds to the output for the \\(i\\)-th training example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf054e6-d1f5-40d7-b5a5-f6889593131e",
   "metadata": {},
   "source": [
    "### 1.  Manual: Gradient descent usign numpy\n",
    "- Prediction: <span style=\"color: Green;\">Manually</span>\n",
    "- Gradients Computation: <span style=\"color: Green;\">Manually</span>\n",
    "- Los Computation: <span style=\"color: Green;\">Manually</span>\n",
    "- Parameter Updates: <span style=\"color: Green;\">Manually</span>\n",
    "\n",
    "```\n",
    "# Compute every step manually\n",
    "# Linear regression\n",
    "# f = w * x\n",
    "# here : f = 2 * x\n",
    "\n",
    "f = w*x  : ignoring bias for now.\n",
    "# let's the weight = 2;  f = 2*x\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3cec67ae-9f36-4c71-8630-4210f7c4f23f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction before training: f(5) = 0.000\n",
      "epoch 1: w = 1.200, loss = 30.00000000\n",
      "epoch 3: w = 1.872, loss = 0.76800019\n",
      "epoch 5: w = 1.980, loss = 0.01966083\n",
      "epoch 7: w = 1.997, loss = 0.00050332\n",
      "epoch 9: w = 1.999, loss = 0.00001288\n",
      "epoch 11: w = 2.000, loss = 0.00000033\n",
      "epoch 13: w = 2.000, loss = 0.00000001\n",
      "epoch 15: w = 2.000, loss = 0.00000000\n",
      "Prediction after training: f(5) = 10.000\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Lets generate some training samples\n",
    "X = np.array([1, 2, 3, 4], dtype=np.float32)\n",
    "# Since our formula is  f = 2*x therefore the valuse are twice of X\n",
    "Y = np.array([2, 4, 6, 8], dtype=np.float32)\n",
    "\n",
    "plt.plot(X,Y,'ok')\n",
    "\n",
    "# Initalise our weigths\n",
    "w = 0.0\n",
    "\n",
    "# # model output: Calculate our model predicetion: $f = w*x$\n",
    "def forward(x):\n",
    "    return w*x\n",
    "\n",
    "# Loss = MSE; Calcualte Loss. Loss depend on predecicted and true value. Using MSE loss. \n",
    "def loss(y, y_predicted):\n",
    "    return ((y_predicted-y)**2).mean()\n",
    "\n",
    "# Calcualte Gradient\n",
    "# MSE = 1/N*(w*x) - y)**2\n",
    "# dJ/dw = 1/N 2*x (w*x-y)\n",
    "def gradient(x, y, y_predicted):\n",
    "    return np.dot(2*x, y_predicted-y).mean()\n",
    "\n",
    "print(f'Prediction before training: f(5) = {forward(5):.3f}')\n",
    "\n",
    "# Trainign\n",
    "learn_rate = 0.01\n",
    "n_iters = 15\n",
    "\n",
    "for epoch in range(n_iters):\n",
    "    # prediction: Forward Pass\n",
    "    y_pred = forward(X)\n",
    "\n",
    "    # Loss \n",
    "    l = loss(Y, y_pred)\n",
    "\n",
    "    # Gradients\n",
    "    dw = gradient(X, Y, y_pred)\n",
    "\n",
    "    # Update the weights using gradeint descent. Go in negative direction\n",
    "    w -= learn_rate*dw\n",
    "\n",
    "    # if epoch % 1==0:\n",
    "    if epoch % 2==0: # print every second Step\n",
    "        print(f'epoch {epoch+1}: w = {w:.3f}, loss = {l:.8f}')\n",
    "\n",
    "print(f'Prediction after training: f(5) = {forward(5):.3f}')   \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9254ee-0861-401c-99f0-9b7e4e1b196e",
   "metadata": {},
   "source": [
    "### 2. Using gradient using PyTorch Autograd\n",
    "- Prediction: <span style=\"color: Green;\">Manually</span>\n",
    "- Gradients Computation: <span style=\"color: Red;\">Autograd</span>\n",
    "- Los Computation: <span style=\"color: Green;\">Manually</span>\n",
    "- Parameter Updates: <span style=\"color: Green;\">Manually</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503e68a8-3eb8-425a-876f-ddf3359fe73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Lets generate some training samples\n",
    "X = torch.tensor([1, 2, 3, 4], dtype=torch.float32)\n",
    "# Since our formula is  f = 2*x therefore the valuse are twice of X\n",
    "Y = torch.tensor([2, 4, 6, 8], dtype=torch.float32)\n",
    "\n",
    "# Initalise our weigths. Since we are interested in claculating the gradeint of loss w.r.t. weight. \n",
    "# Therefore, we need to specify that it requires gradient calculation`requires_grad=True`\n",
    "w = torch.tensor(0.0, dtype=torch.float32, requires_grad=True)\n",
    "\n",
    "# Calculate our model predicetion: $f = w*x$\n",
    "def forward(x):\n",
    "    return w*x\n",
    "\n",
    "# Calcualte Loss. Loss depend on predecicted and true value. Using MSE loss. Loss = MSE\n",
    "def loss(y, y_predicted):\n",
    "    return ((y_predicted-y)**2).mean()\n",
    "\n",
    "# Calcualte Gradient: This step is p[erfromed using PyTorch Autograd\n",
    "\n",
    "print(f'Prediction before training: f(5) = {forward(5):.3f}')\n",
    "\n",
    "# Training\n",
    "learn_rate = 0.01\n",
    "n_iters = 15\n",
    "\n",
    "for epoch in range(n_iters):\n",
    "    # prediction: Forward Pass\n",
    "    y_pred = forward(X)\n",
    "\n",
    "    # Loss \n",
    "    l = loss(Y, y_pred)\n",
    "\n",
    "    # Gradients =  backward pass. Rememebr in Computational graph we did backward pass to calcualte the gradeints\n",
    "    dw = l.backward()  # Gradeint of loss w.r.t. w  dl/dw\n",
    "\n",
    "    # Update the weights using gradient descent. Be careful\n",
    "    with torch.no_grad():\n",
    "        w -= learn_rate*w.grad\n",
    "\n",
    "    # zero the gradeints to avoid accumulation\n",
    "    w.grad.zero_()\n",
    "\n",
    "    # if epoch % 1==0:\n",
    "    if epoch % 2==0: # print every second Step\n",
    "        print(f'epoch {epoch+1}: w = {w:.3f}, loss = {l:.8f}')\n",
    "\n",
    "print(f'Prediction after training: f(5) = {forward(5):.3f}')   \n",
    "\n",
    "# We will get less accuracy comapred to the numpy implementation numercially. As the gradeint calculation is not as exact as we did in numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe84dae-9ec5-4bad-ba5b-cfc1912a8740",
   "metadata": {},
   "source": [
    "### 3. Using pytorch loss and optimizer\n",
    "- Prediction: <span style=\"color: Green;\">Manually</span>\n",
    "- Gradients Computation: <span style=\"color: Red;\">Autograd</span>\n",
    "- Los Computation: <span style=\"color: Red;\">PyTorch Loss</span>\n",
    "- Parameter Updates: <span style=\"color: Red;\">PyTorch Optimizer</span>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65614f2-eca0-4d84-bab8-0d77bc773065",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "General Training Pipeline in PyTorch. We have three steps.\n",
    "(1) Design model(input, output size, forward pass)\n",
    "(2) COnstruct Loss and Optimizer\n",
    "(3) Training Loop\n",
    "\n",
    "- Forward Pass: Compute the prediction\n",
    "- Backward pass: Gradients\n",
    "- Update weights\n",
    "- Iterate for number of times\n",
    "\n",
    "We will use neural network module from pytorch\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Lets generate some training samples\n",
    "X = torch.tensor([1, 2, 3, 4], dtype=torch.float32)\n",
    "Y = torch.tensor([2, 4, 6, 8], dtype=torch.float32)\n",
    "\n",
    "w = torch.tensor(0.0, dtype=torch.float32, requires_grad=True)\n",
    "\n",
    "# Model Prediction\n",
    "def forward(x):\n",
    "    return w*x\n",
    "\n",
    "# print the prediction efore the training, using f string. We want to predict the value 5, whcih shoudl be 10.\n",
    "print(f'Prediction before training: f(5) = {forward(5):.3f}')\n",
    "\n",
    "# Training\n",
    "learn_rate = 0.01\n",
    "n_iters = 15\n",
    "\n",
    "loss = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD([w], lr=learn_rate)\n",
    "\n",
    "for epoch in range(n_iters):\n",
    "    # prediction: Forward Pass\n",
    "    y_pred = forward(X)\n",
    "\n",
    "    # Loss \n",
    "    l = loss(Y, y_pred)\n",
    "\n",
    "    # Gradients =  backward pass. Rememebr in Computational graph we did backward pass to calcualte the gradeints\n",
    "    dw = l.backward()  # Gradeint of loss w.r.t. w  dl/dw\n",
    "\n",
    "    # *** Here we change** Dont need to manually update the weights\n",
    "    optimizer.step()\n",
    "\n",
    "    # zero the gradeints to avoid accumulation\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # if epoch % 1==0:\n",
    "    if epoch % 2==0: # print every second Step\n",
    "        print(f'epoch {epoch+1}: w = {w:.3f}, loss = {l:.8f}')\n",
    "\n",
    "print(f'Prediction after training: f(5) = {forward(5):.3f}')   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b2677a-7428-4137-a244-7ed0f8773999",
   "metadata": {},
   "source": [
    "### 4. Using everything from pytorch\n",
    "- Prediction: <span style=\"color: Red;\">PyTorch Model</span>\n",
    "- Gradients Computation: <span style=\"color: Red;\">Autograd</span>\n",
    "- Los Computation: <span style=\"color: Red;\">PyTorch Loss</span>\n",
    "- Parameter Updates: <span style=\"color: Red;\">PyTorch Optimizer</span>\n",
    "\n",
    "To use `nn.Linear()` the data shape  need to be in specific dimension. It should be 2D arrays where the number of rows - number of samples and for each rows we have features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac970c9b-da62-4560-9553-ce7eb1aa6df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Lets generate some training samples\n",
    "X = torch.tensor([[1], [2], [3], [4]], dtype=torch.float32)\n",
    "Y = torch.tensor([[2], [4], [6], [8]]], dtype=torch.float32)\n",
    "\n",
    "X_test = toch.tensor([5], dtype=torch.float32)\n",
    "n_samples, n_features = X.shape\n",
    "print(n_samples, n_features)\n",
    "\n",
    "# We dont need to define weights, pytorch knows the parematers. Also change the forward fucntioon to pytorch\n",
    "# usually we have to design this modell. but for this sim;le example, there could be only one layer.\n",
    "input_size = n_features\n",
    "output_size = n_features\n",
    "\n",
    "model = nn.Linear(input_size, output_size)\n",
    "\n",
    "print(f'Prediction before training: f(5) = {model(X_test).item():.3f}') # Change Here\n",
    "\n",
    "# Training\n",
    "learn_rate = 0.01\n",
    "n_iters = 15\n",
    "\n",
    "loss = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learn_rate)  # Change Here\n",
    "\n",
    "for epoch in range(n_iters):\n",
    "    # prediction: Forward Pass\n",
    "    y_pred = model(X)\n",
    "\n",
    "    # Loss \n",
    "    l = loss(Y, y_pred)\n",
    "\n",
    "    # Gradients =  backward pass. Rememebr in Computational graph we did backward pass to calcualte the gradeints\n",
    "    dw = l.backward()  # Gradeint of loss w.r.t. w  dl/dw\n",
    "\n",
    "    # *** Here we change** Dont need to manually update the weights\n",
    "    optimizer.step()\n",
    "\n",
    "    # zero the gradeints to avoid accumulation\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # if epoch % 1==0:\n",
    "    # if epoch % 2==0: # print every second Step\n",
    "    if epoch % 10==0:\n",
    "        [w, b] = model.parameters()        \n",
    "        print('epoch ', epoch+1, ': w = ', w[0][0].item(), ' loss = ', l)\n",
    "\n",
    "print(f'Prediction before training: f(5) = {model(X_test).item():.3f}')  \n",
    "\n",
    "# Final oyutput is not that accurate because the initialization is random and also the optimizer may not be that good for this problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f774d0a-b18f-4a35-87c9-36e4b8e955ee",
   "metadata": {},
   "source": [
    "### Use Custom Model instead `nn.Linear`\n",
    "Linear regression\n",
    "f = w * x \n",
    "\n",
    "here : f = 2 * x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afbeea16-8441-4f0f-8704-edb70b43b79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 0) Training samples, watch the shape!\n",
    "X = torch.tensor([[1], [2], [3], [4]], dtype=torch.float32)\n",
    "Y = torch.tensor([[2], [4], [6], [8]]], dtype=torch.float32)\n",
    "\n",
    "X_test = toch.tensor([5], dtype=torch.float32)\n",
    "n_samples, n_features = X.shape\n",
    "print(n_samples, n_features)\n",
    "\n",
    "# 1) Design Model, the model has to implement the forward pass!\n",
    "# Here we can use a built-in model from PyTorch\n",
    "input_size = n_features\n",
    "output_size = n_features\n",
    "\n",
    "# we can call this model with samples X\n",
    "# model = nn.Linear(input_size, output_size)\n",
    "\n",
    "class LinearRegression(nn.Module):\n",
    "    # This will get init method which has self\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        # Call Super class\n",
    "        super(LinearRegression, self).__init__()\n",
    "        # Define Layers\n",
    "        self.lin = nn.Linear(input_dim, output_dim)\n",
    "\n",
    "    # We have to implement Forward Pass in our model class\n",
    "    def forward(self, x):\n",
    "        return self.lin(x)\n",
    "\n",
    "model = LinearRegression(input_size, output_size)\n",
    "\n",
    "\n",
    "print(f'Prediction before training: f(5) = {model(X_test).item():.3f}') # Change Here\n",
    "\n",
    "# 2) Define loss and optimizer\n",
    "learn_rate = 0.01\n",
    "n_iters = 100\n",
    "\n",
    "loss = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learn_rate)  # Change Here\n",
    "\n",
    "# 3) Training loop\n",
    "for epoch in range(n_iters):\n",
    "    # prediction: Forward Pass with our model\n",
    "    y_pred = model(X)\n",
    "\n",
    "    # Loss \n",
    "    l = loss(Y, y_pred)\n",
    "\n",
    "    # Gradients =  backward pass. Rememebr in Computational graph we did backward pass to calcualte the gradeints\n",
    "    dw = l.backward()  # Gradeint of loss w.r.t. w  dl/dw\n",
    "\n",
    "    # update weights  \n",
    "    optimizer.step() # Change Here: Dont need to manually update the weights\n",
    "\n",
    "    # zero the gradeints after updating to avoid accumulation\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    if epoch % 10==0:\n",
    "        [w, b] = model.parameters()        \n",
    "        print('epoch ', epoch+1, ': w = ', w[0][0].item(), ' loss = ', l)\n",
    "\n",
    "print(f'Prediction before training: f(5) = {model(X_test).item():.3f}')  \n",
    "\n",
    "# Final oyutput is not that accurate because the initialization is random and also the optimizer may not be that good for this problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf07d4f-72ab-4d43-adce-baf21bbb834d",
   "metadata": {},
   "source": [
    "### Final Summary: Linear Regression using PyTorch\n",
    "0. Prepare Data\n",
    "1. Design Model (input size, output size, forward pass)\n",
    "2. Construct Loss and optimizer\n",
    "3. Training Loop\n",
    "    - Forward Pass: Compute Prediction and Loss\n",
    "    - Backward Pass: Gradients\n",
    "    - Update Weights\n",
    "\n",
    "Here we implement liinear regression again usign PyTorch\n",
    "\n",
    "### Generating synthetic Data\n",
    "Use `make_regression()` to generate dataset suitable for regression tasks, where there is a relationship between input features $(X)$ and a continuous target $(y)$. Here is the code line. Let's understand each arguments\n",
    "`X_numpy, y_numpy = datasets.make_regression(n_samples=100, n_features=1, noise=20, random_state=1)`\n",
    "\n",
    "- `n_samples=100`: Number of samples (data points) to generate. Generate 100 rows of data.\n",
    "- `n_features=1`: Number of features (independent variables). Generate a dataset with one feature per sample.\n",
    "- `noise=20`: Adds random noise to the output values (y) so the data is not perfectly linear.\n",
    "- `random_state=1`: Ensures that the dataset generated is reproducible. If you run the same code again, you will get the same results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4481814e-0e5e-4aad-be9f-93b945766ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 0 Prepare Data: use `make_regression` from `sklearn.datasets` to generate a synthetic regression dataset.\n",
    "X_numpy, y_numpy =  datasets.make_regression(n_samples=100, n_features=1, noise=20, random_state=1)\n",
    "print(X_numpy[:5], y_numpy[:5])\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "# X = torch.tensor(X_numpy, dtype=torch.float32)  # Shape: (100, 1)\n",
    "# y = torch.tensor(y_numpy, dtype=torch.float32).view(-1, 1)  # Shape: (100, 1) for regression\n",
    "# For multi-class classification:\n",
    "# y_classification = torch.randint(0, 3, (100,))  # Example with 3 classes, Shape: (100,)\n",
    "\n",
    "# compert the data to toch and float32 from double\n",
    "X = torch.from_numpy(X_numpy.astype(np.float32))\n",
    "X = torch.from_numpy(y_numpy.astype(np.float32))\n",
    "y = y.view(y.shape[0], 1)# Reshape the data because currently it has 1 row and we want to make it a column vector. So we want to put each valu in 1 column\n",
    "\n",
    "n_samples, n_features = X.shape\n",
    "print(n_samples, n_features)\n",
    "\n",
    "# 1. Model (input size, output size, forward pass)\n",
    "# in linear regression case its just a 1 lyaer so we can use builtin model\n",
    "input_size = n_features\n",
    "output_size = 1\n",
    "model = nn.Linear(input_size, output_size)\n",
    "\n",
    "# 2. Loss and optimizer: Lets call MSELoss function\n",
    "learning_rate = 0.01\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# 3. Training Loop\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    # Forward pass and Loss\n",
    "    y_predicted = model(X)\n",
    "    loss = criterion(y_predicted, y) # this need actual labels and prediceted values\n",
    "    # backward Pass\n",
    "    loss.backward()\n",
    "    \n",
    "    # update\n",
    "    optimizer.step()\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    if (epoch+1) %10 ==0:\n",
    "        print(f'epoch: {epoch+1}, loss = {loss.item():.4f}')\n",
    "\n",
    "# plot\n",
    "predicted = model(X).detach() # detach this to prevent this to be tracked from cmputaitonal graph. Beacuse the requires_grad was true. After detaching it creates new tensor with requires_grad=false\n",
    "plt.plot(X_numpy, y_numpy, 'ro')\n",
    "plt.plot(X_numpy, predicted, 'b')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3308f10-45cd-4231-9cb1-a365da5b2e1f",
   "metadata": {},
   "source": [
    "# Test Exercise for Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "999ec29a-b1cc-493a-9813-bbde986ee084",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example: Linear Regression in Python using **scikit-learn** to predict housing prices:\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.datasets import make_regression\n",
    "\n",
    "# Generate synthetic regression data\n",
    "X, y = make_regression(n_samples=100, n_features=1, noise=20, random_state=42)\n",
    "\n",
    "# Create a Linear Regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Train the model\n",
    "model.fit(X, y)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X)\n",
    "\n",
    "# Plot the results\n",
    "plt.scatter(X, y, color='blue', label=\"Actual data\")\n",
    "plt.plot(X, y_pred, color='red', linewidth=2, label=\"Regression Line\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Feature (X)\")\n",
    "plt.ylabel(\"Target (y)\")\n",
    "plt.title(\"Linear Regression Example\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9681f771-34b0-41e9-9f86-89d58aee0a3a",
   "metadata": {},
   "source": [
    "### In Pytorch: Write above code in PyTorch\n",
    "- Generate Synthetic Data using make_regression() (same as in scikit-learn).\n",
    "- Convert Data to PyTorch Tensors for model training.\n",
    "- Define a Linear Regression Model using nn.Linear().\n",
    "- Specify Loss Function (MSELoss) and Optimizer (SGD).\n",
    "- Train the Model using Gradient Descent.\n",
    "- Make Predictions using the trained model.\n",
    "- Visualize Results with matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43b8773-f08e-4ff9-8888-2238d06e13b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_regression\n",
    "\n",
    "# Generate synthetic regression data\n",
    "X_numpy, y_numpy = make_regression(n_samples=100, n_features=1, noise=20, random_state=42)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X = torch.tensor(X_numpy, dtype=torch.float32)  # Shape: (100, 1)\n",
    "y = torch.tensor(y_numpy, dtype=torch.float32).view(-1, 1)  # Shape: (100, 1)\n",
    "\n",
    "# Define the Linear Regression model\n",
    "class LinearRegressionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LinearRegressionModel, self).__init__()\n",
    "        self.linear = nn.Linear(1, 1)  # 1 input feature, 1 output\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "# Initialize model\n",
    "model = LinearRegressionModel()\n",
    "\n",
    "# Define loss function (Mean Squared Error) and optimizer (Gradient Descent)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)  # Learning rate 0.01\n",
    "\n",
    "# Training loop\n",
    "epochs = 1000\n",
    "for epoch in range(epochs):\n",
    "    optimizer.zero_grad()  # Clear previous gradients\n",
    "    y_pred = model(X)  # Forward pass\n",
    "    loss = criterion(y_pred, y)  # Compute loss\n",
    "    loss.backward()  # Backpropagation\n",
    "    optimizer.step()  # Update weights\n",
    "\n",
    "    # Print loss every 100 epochs\n",
    "    if (epoch+1) % 100 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# Make predictions\n",
    "with torch.no_grad():\n",
    "    y_pred = model(X)\n",
    "\n",
    "# Plot the results\n",
    "plt.scatter(X_numpy, y_numpy, color='blue', label=\"Actual data\")\n",
    "plt.plot(X_numpy, y_pred.numpy(), color='red', linewidth=2, label=\"Regression Line\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Feature (X)\")\n",
    "plt.ylabel(\"Target (y)\")\n",
    "plt.title(\"Linear Regression using PyTorch\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7598d390-98da-482b-a21e-a11e364d89f0",
   "metadata": {},
   "source": [
    "##  **Thank You!**   \n",
    "###  Happy Coding & Keep Learning! \n",
    "\n",
    "## <span style=\"color: yellow;\">Next: Logistic Regression</span>\n",
    "\n",
    "### Logistic Regression\n",
    "- Logistic Regression works by applying the `sigmoid (logistic) function` to a linear equation. This converts continuous values into probabilities between 0 and 1.\n",
    "- Logistic Regression is used for classification, not regression.\n",
    "- It converts linear predictions into probabilities using the `sigmoid function`.\n",
    "- Binary Logistic Regression is for two-class problems, while Multiclass Logistic Regression `(Softmax)` handles multiple classes.\n",
    "- The model is trained using `cross-entropy loss` and optimized with techniques like gradient descent.\n",
    "- It is interpretable, computationally efficient, and widely used in ML applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2afdb8d6-f160-4e90-ac3c-2da37b2dd6fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
