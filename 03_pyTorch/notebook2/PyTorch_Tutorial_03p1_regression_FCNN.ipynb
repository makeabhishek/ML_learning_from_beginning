{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e939e163-e70c-4a0a-8b4a-d6a7bd87b59e",
   "metadata": {},
   "source": [
    "Build a Simple Neural Network from Scratch with PyTorch\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\".\\images\\gradeint_descent.PNG\" alt=\"Computational Graph\" width=\"700\">\n",
    "</div>\n",
    "\n",
    "## Gradeint Descent Review\n",
    "- Lets assume we have three data points $(x_1,y_1)$, $(x_2,y_2)$ and $(x_3,y_3)$ in the $xy$ coordinate system.\n",
    "- The goal is to find the relation between $x$ and $y$.\n",
    "- Here we can see these points are at $45^o$, but if the points are more complex. how to find the solution.\n",
    "- We can make a hypothesis to find the solution. So any ML agorithm starts with a hypothesis $h(x)=\\theta_1*(x)$, the output is connected with input by multiplying it with some parameters or weights $\\theta_1$ with input $x$.\n",
    "- Than we have to define the loss function how good or bad is the paratmeter  $\\theta_1$ is given the dataset that we have. Here we use Mean squared error (MSE), which is obtained by subtracting between the prediction $\\theta_1(x)_{i}$ abd the actial value $y_i$ and square it.\n",
    "$$J(\\theta_1)=\\frac{1}{2} \\sum_{i=1}{3}(\\theta_1(x)_{i} - y_i)^2$$\n",
    "- Now the objective is to find the value of $\\theta_1$ that leads the minimum vallue of cost fucntion $J(\\theta_1)$\n",
    "\n",
    "$$\\arg\\min_{\\theta_1} (J(\\theta_1))$$\n",
    "\n",
    "- $\\arg\\min$ means that we are looking for minimum value of the cost fucntion but indeed we are looking at what input value $\\theta_1$ leads to the minimum value of the function.\n",
    "- If we plot the cost fucntion $J(\\theta_1)$ that we have w.r.t. $\\theta_1$ we can atleast see where the fucntion is minimum (visually), whcih is at 1. This is what we knew, because slope of $45^o$ line is 1. But what if the cost funtion is modre complex.\n",
    "- To find the minimum we look the derivaive of function. Derivative is intsantaneous rate of change. If I want to find the minimum value of fucntion. We can find the derivative at the initilization random point. The gradeitn is basically a tangent to that point and see what is the value of derivative $+$ or $-$. Depnding on that we check should we go left or right.\n",
    "- If the derviative is negative, this means that we ahve to go to right to get the smaller value of this fucntion\n",
    "- Repeat this process for point 2. go towards right\n",
    "- when the gradeint is approx zero we stop.\n",
    "\n",
    "## General formula to update the values\n",
    "$$\\theta_1 \\leftarrow \\theta_1 - \\alpha J'(\\theta_1)$$\n",
    "- where $\\alpha$ is learnign rate, $\\theta_1$ is the current value $J'(\\theta_1)$ derivative at that point.\n",
    "- negative sign because we want to minimize the function. As we are going towards right.\n",
    "- Lets calcualte the derivative $J'(\\theta_1) $ of objective function w.r.t. model parameters i.e. weights, not input or output using chain rule. Input and output are given and fixed so nothing to optimize\n",
    "  $$ J'(\\theta_1) =\\frac{1}{2}\\sum_{i=1}^{n} 2(\\theta_1*x_i - y_i)x_i = \\sum_{i=1}^{n} 2(\\theta_1*x_i - y_i)x_i$$\n",
    "- $\\theta_1$ is the model parameters that we want to optimize. In nn these are weights and biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6794ffab-dbe2-4c8b-b078-c25f42ac6d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Given data\n",
    "x = np.array([1, 2, 3])\n",
    "y_true = np.array([1, 2, 3])\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(x,y_true, 'ok')\n",
    "plt.title('n=3 training data points')\n",
    "plt.show()\n",
    "\n",
    "# Define MSE function\n",
    "def mse(y_true, y_pred):\n",
    "    return np.mean((y_true - y_pred) ** 2)\n",
    "\n",
    "# Generate predicted values for visualization\n",
    "y_pred_range = np.linspace(-10, 10, 10)  # Range of predicted values\n",
    "mse_values = [mse(y_true, np.full_like(y_true, yp)) for yp in y_pred_range]\n",
    "\n",
    "# Plot MSE vs. predicted values\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(y_pred_range, mse_values, label=\"MSE Curve\", color=\"b\")\n",
    "plt.xlabel(\"Predicted Value\")\n",
    "plt.ylabel(\"Mean Squared Error (MSE)\")\n",
    "plt.title(\"MSE vs. Predicted Value\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0f7caa-6ce0-4727-a0f1-f2f110d0439d",
   "metadata": {},
   "source": [
    "# Gradient Descent to Minimize the Cost Function (MSE)\n",
    "\n",
    "**Gradient Descent** is an optimization algorithm used to minimize a given cost function by iteratively adjusting parameters in the direction of the steepest descent (negative gradient). For **Mean Squared Error (MSE)**, the goal is to find the optimal \\( \\theta \\) that minimizes:\n",
    "\n",
    "$$\n",
    "J(\\theta) = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2\n",
    "$$\n",
    "\n",
    "where:\n",
    "\n",
    "- $J(\\theta)$ is the **cost function (MSE)**.\n",
    "- $y_i $ is the **true value**.\n",
    "- $ \\hat{y}_i$ is the **predicted value**.\n",
    "- $ n $ is the **number of data points**.\n",
    "\n",
    "---\n",
    "\n",
    "## Gradient Descent Update Rule\n",
    "\n",
    "The update rule for gradient descent is:\n",
    "\n",
    "$$\n",
    "\\theta = \\theta - \\alpha \\frac{dJ}{d\\theta}\n",
    "$$\n",
    "\n",
    "where:\n",
    "\n",
    "- $\\alpha $ (learning rate) controls the **step size**.\n",
    "- $\\frac{dJ}{d\\theta} $ is the **gradient of the cost function**.\n",
    "\n",
    "For **linear regression**, the gradient of MSE with respect to \\( \\theta \\) is:\n",
    "\n",
    "$$\n",
    "\\frac{dJ}{d\\theta} = -\\frac{2}{n} \\sum (y_i - \\hat{y}_i)\n",
    "$$\n",
    "\n",
    "\n",
    "# Gradient Descent Algorithm\n",
    "\n",
    "Gradient Descent is an optimization algorithm used to minimize a given cost function by iteratively adjusting parameters in the direction of the steepest descent (negative gradient).\n",
    "\n",
    "## **Algorithm Steps for Gradient Descent**\n",
    "1. **Initialize Parameters:**\n",
    "   - Choose an initial guess for **$\\theta $ (weights/parameters)**.\n",
    "   - Set the **learning rate** $\\alpha $.\n",
    "   - Define the number of iterations (or stopping criteria).\n",
    "\n",
    "2. **Compute Predictions:**\n",
    "   - Calculate the predicted values **$\\hat{y}$** using the current parameters:\n",
    "     $$\n",
    "     \\hat{y} = \\theta x\n",
    "     $$\n",
    "\n",
    "3. **Compute the Cost Function:**\n",
    "   - Evaluate the Mean Squared Error $(MSE)$ cost function:\n",
    "     $$\n",
    "     J(\\theta) = \\frac{1}{m} \\sum_{i=1}^{m} (y_i - \\hat{y}_i)^2\n",
    "     $$\n",
    "   - Store the cost function values (optional, for visualization).\n",
    "\n",
    "4. **Compute the Gradient:**\n",
    "   - Calculate the derivative of the cost function with respect to **\\( \\theta \\)**:\n",
    "     $$\n",
    "     \\frac{dJ}{d\\theta} = -\\frac{2}{m} \\sum (y_i - \\hat{y}_i) x_i\n",
    "     $$\n",
    "\n",
    "5. **Update the Parameters:**\n",
    "   - Update **\\( \\theta \\)** using the gradient descent formula:\n",
    "     $$\n",
    "     \\theta = \\theta - \\alpha \\frac{dJ}{d\\theta}\n",
    "     $$\n",
    "\n",
    "6. **Repeat Steps 2 to 5:**\n",
    "   - Continue iterating until:\n",
    "     - A **convergence criteria** is met (e.g., the change in cost function is minimal).\n",
    "     - The **maximum number of iterations** is reached.\n",
    "\n",
    "7. **Return the Optimal Parameters:**\n",
    "   - The final value of **$ \\theta $** is the one that minimizes the cost function.\n",
    "\n",
    "---\n",
    "\n",
    "## **Notes:**\n",
    "- The **learning rate** $ \\alpha $ should be chosen carefully:\n",
    "  - Too large: The algorithm may **diverge**.\n",
    "  - Too small: The algorithm may **converge slowly**.\n",
    "- Gradient Descent can be **Batch Gradient Descent**, **Stochastic Gradient Descent (SGD)**, or **Mini-batch Gradient Descent** depending on the amount of data used per update.\n",
    "\n",
    "---\n",
    "\n",
    "This algorithm is widely used in **machine learning**, particularly in **linear regression**, **logistic regression**, and **neural networks**.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c2110e-d6eb-4b6b-8b68-23cd7fb16021",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Given dataset\n",
    "x = np.array([1, 2, 3])\n",
    "y_true = np.array([1, 2, 3])\n",
    "\n",
    "# Initialize parameters\n",
    "theta = 0.0  # Initial guess\n",
    "alpha = 0.1  # Learning rate\n",
    "iterations = 100  # Number of gradient descent steps\n",
    "\n",
    "# Store cost values for visualization\n",
    "cost_history = []\n",
    "\n",
    "# Gradient Descent Algorithm\n",
    "for i in range(iterations):\n",
    "    y_pred = theta * x  # Predicted value\n",
    "    error = y_pred - y_true  # Error\n",
    "    cost = np.mean(error ** 2)  # Compute MSE cost\n",
    "    cost_history.append(cost)  # Store cost function value\n",
    "    \n",
    "    # Compute gradient (derivative of cost function)\n",
    "    gradient = (2 / len(x)) * np.sum(error * x)\n",
    "    \n",
    "    # Update theta using gradient descent update rule\n",
    "    theta -= alpha * gradient\n",
    "\n",
    "# Final optimized theta\n",
    "print(\"Optimized theta:\", theta)\n",
    "\n",
    "# Plot the cost function over iterations\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(range(iterations), cost_history, label=\"Cost Function (MSE)\", color=\"b\")\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"MSE Cost\")\n",
    "plt.title(\"Gradient Descent: Cost Function vs Iterations\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba7e09dc-ed2f-4e3f-99f9-87b8d5778e4e",
   "metadata": {},
   "source": [
    "## Multi dimensional problem\n",
    "If we have multivariate fucntion. In this case we have to use parital derivative instead of derivate. than find the Jacobian\n",
    "$$\\theta \\leftarrow \\theta - \\alpha \\nabla J(\\theta)$$\n",
    "- $\\nabla J(\\theta)$ is gradeint\n",
    "$$\n",
    "\\nabla J(\\theta) = \n",
    "\\begin{bmatrix}\n",
    "\\frac{\\partial J}{\\partial \\theta_1} \\\\\n",
    "\\frac{\\partial J}{\\partial \\theta_2} \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "### if we have a lot of samples \n",
    "Than we canot use full data at once. We divide the data into batches and update the parameter \n",
    "- divide the data into bathes $\\rightarrow$ update the parameter $\\rightarrow$ repeat (numper of epocs)\n",
    "- we have to tune hyper parameter, the size of batch and number of epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b0be12d-2946-4c79-a9ef-f4f8ac328c56",
   "metadata": {},
   "source": [
    "---\n",
    "# Creat a simple Neural Network \n",
    "---\n",
    "## Step 0:  Generate synthetic Data\n",
    "Lets assume that the output $y$ is linear combination of weights $w_1$ and $w_2$. Previously we call it as $\\theta_1$ and $\\theta_2$\n",
    "$$ y = w_1 x_1 + w_2 x_2 + b $$\n",
    "- This is a general framework for linear regression\n",
    "- Using linear algebra, We can write this as inner product of weights and inputs (inputs are kind of features, or )\n",
    "$$\n",
    "y <\n",
    "\\begin{bmatrix}\n",
    "w_1 \\\\\n",
    "w_2 \\\\\n",
    "\\end{bmatrix},\n",
    "\\begin{bmatrix}\n",
    "x_1 \\\\\n",
    "x_2 \\\\\n",
    "\\end{bmatrix}\n",
    "> + b =\n",
    "\\begin{bmatrix}\n",
    "x_1 & x_2 \\\\\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "w_1 \\\\\n",
    "w_2 \\\\\n",
    "\\end{bmatrix} +b\n",
    "$$\n",
    "\n",
    "for a complete dataset we stack the feature vector $[x_1 x_2]$ whcih is called $X$, where each row corresponds to sample and each column coresponds to feature\n",
    "$$\n",
    "y =\n",
    "\\begin{bmatrix}\n",
    "\\vdots \\\\\n",
    "X \\\\\n",
    "\\vdots \\\\\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "w_1 \\\\\n",
    "w_2 \\\\\n",
    "\\end{bmatrix} +b\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602c7ed8-1b99-4f08-b376-14f35410eb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils import data\n",
    "\n",
    "def synthetic_data(w, b, num_examples):\n",
    "    \"\"\" Generate y = wx + b + noise \"\"\"\n",
    "    X = torch.normal(0,1, (num_examples, len(w)))\n",
    "    y = torch.matmul(X,w) + b # here it works because of broadcasting. b is added to all elements of the result of multiplication\n",
    "    y += torch.normal(0, 0.01, y.shape)\n",
    "    return X,y.reshape((-1,1))\n",
    "\n",
    "\n",
    "true_w = torch.tensor([2, -3.4])\n",
    "true_b = 4.2\n",
    "# features are X and  labels are y\n",
    "features, labels = synthetic_data(true_w, true_b, 1000)\n",
    "print(features.shape, labels.shape) # for each sampel we ahve 1 output value y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb42922-9641-4502-8316-c86bdfa84946",
   "metadata": {},
   "source": [
    "## Step 1: Reading the dataset\n",
    "We use `torch.utils` to construct batch size of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd67253e-1235-4bd4-9e49-676e6cde1458",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_array(data_arrays, batch_size, is_train=True):\n",
    "    \"\"\"Construct a PyToech data Iterator\"\"\"\n",
    "    dataset = data.TensorDataset(*dat_arrays)\n",
    "    return data.DataLoader(dataset, batch_size, shuffle=is_train)\n",
    "\n",
    "batch_size = 10 # we have 1000 samples and 10 batches so there will be 100\n",
    "# This gives us an iteratable object. Every time we get 10 rows of X and corresponding y\n",
    "data_iter =  load_array((features, labels), batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a775909e-de03-4235-b021-452130eefd3d",
   "metadata": {},
   "source": [
    "## Step 2: Defining the model\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\".\\images\\fcnn_simple.PNG\" alt=\"Computational Graph\" width=\"350\">\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f53f63-2795-4c9e-ab9e-90c92af3eb48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# `nn` is abbrevaition for neural networks\n",
    "from torch import nn\n",
    "\n",
    "# the fully connected lauer is defined in the Linear class\n",
    "net = nn.Sequential(nn.Linear(2,1)) # 2 neuron in input layer and 1 neuron in output layer\n",
    "# NOW WE HAVE ACCESS TO WEIGHTS AND BIAS. To access first layer\n",
    "print(net[0].weight, net[0].bias) # weight has two element and bias has one element. requires_grad is already set true, which we need for autograd\n",
    "\n",
    "# We can also initialize w1, w2 and b\n",
    "net[0].weight.data.normal_(0,0.01) # we are initiliising with normal distributed data with mean 0 and variance 0.01\n",
    "net[0].bias.data.fill_(0)\n",
    "\n",
    "# As we have only one layer if we try to get value net[1].weight, we will get error. As there is only one layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3abbbab6-10ab-404c-a3fe-b986350f3348",
   "metadata": {},
   "source": [
    "## Step 3: Defining the cost fucntion (loss) and optimizer\n",
    "\n",
    "- `net.parameters()` will take all the parameter i.e., weights and bias `net` is our neural network that we defined earlier\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7ea326-99a8-48f9-b71f-9be5f4f4f221",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.03)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73cddbb-c002-4ef8-b946-e99cfa6cf68a",
   "metadata": {},
   "source": [
    "## Step 4: Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6faa98be-9de1-45b9-9241-b2a964c50534",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 3\n",
    "for epoch in range(num_epochs):\n",
    "    for X, y in data_iter:\n",
    "        # reading only one mini batch, whcih is lioaded usign data loader\n",
    "        l = loss(net(X), y)\n",
    "        trainer.zero_grad() # empty the gradeint\n",
    "        l.backward() # find new gradeint for the loss fucntion\n",
    "        optimizer.step() # update formula for SGD\n",
    "    l = loss(net(features), labels) # See the performance for the estimated data (features) with true data (lables)\n",
    "    print(f'epoch {epoch +1 }, loss {l:f}')\n",
    "\n",
    "# At any point we can access the weight and bias\n",
    "w = net[0].weight.data\n",
    "print('error in estimating w:', true_w - w.reshape(true.w.shape))\n",
    "b = net[0].bias.data\n",
    "print('error in estimating b:', true_b - b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68136968-6507-4016-8b7c-ef5282c0d0ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
