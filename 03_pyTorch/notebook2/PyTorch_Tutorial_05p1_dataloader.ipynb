{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf81c5e6-fa4e-4df8-a836-37059d176c96",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center; font-size: 32px; font-weight: bold;\">\n",
    "    Dataset, DataLoader Classes, Dataset Transforms - Batch Training\n",
    "</div>\n",
    "\n",
    "we see how we can use the built-in `Dataset` and `DataLoader` classes and improve our pipeline with batch training. \n",
    "- Dataset and DataLoader\n",
    "- Automatic batch calculation\n",
    "- Batch optimization in training loop\n",
    "\n",
    "---\n",
    "\n",
    "#### Conventional Data loading\n",
    "So far our code is simple. \n",
    "- We loaded dataset from a csv file.\n",
    "- Ee have training loop.\n",
    "- We optimize the model based on whole dataset (Forward + Backward + weight Update). this can be time consuming if we do gradeint calcaulation on wholele data and sometimes inefficient to load full data at once. A better way for large datasets is to dovode the large samples in to small batches. \n",
    "\n",
    "```\n",
    "data = numpy.loadtxt('wine.csv')\n",
    "# Training Loop\n",
    "for epoch in range(100):\n",
    "    X, y = data\n",
    "    # Forward + Backward + weight Update\n",
    "```\n",
    "---\n",
    "#### Batch Datasets\n",
    "In this case the trainingn loop will be\n",
    "```\n",
    "# Training Loop\n",
    "for epoch in range(100):\n",
    "    # Loop over all batches\n",
    "    for i in range(total_batches):\n",
    "        X_batch, y_batch = ...\n",
    "        # We do optimization only for the current batch of data\n",
    "\n",
    "    # --> Use Dataset and Dataloader to load `wine.csv`\n",
    "```\n",
    "We can use PyTorch Dataset and Dataloader classes. It will do tha batch calcualtins and iterations.\n",
    "\n",
    "### Terminologies in batch training\n",
    "- epoch = one forward and backward pass of ALL training samples\n",
    "- batch_size = number of training samples used in one forward/backward pass\n",
    "- number of iterations = number of passes, each pass (forward+backward) using [batch_size] number of sampes\n",
    "- e.g : 100 samples, batch_size=20 -> 100/20=5 iterations for 1 epoch\n",
    "\n",
    "### --> DataLoader can do the batch computation for us\n",
    "```\n",
    "# Implement a custom Dataset:\n",
    "# inherit Dataset\n",
    "implement __init__ , __getitem__ , and __len__\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d100c6e1-5117-431f-abba-cdd1a652f2d9",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (773188495.py, line 18)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[1], line 18\u001b[1;36m\u001b[0m\n\u001b[1;33m    xy = np.loadtxt('./data/wine.csv', delimeter=, ,dtype = np.float32, skiprows=1)\u001b[0m\n\u001b[1;37m                                                 ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader #  A base class for custom datasets in PyTorch.\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# Dataset: We have wine dataset.  \n",
    "# 1st row: Header\n",
    "# We want to predict wine categories. There are three wine categories: 1, 2, 3\n",
    "# The classes are in the first column and Features are in other columns\n",
    "\n",
    "# So here we are creating a custom dataset class, where __init__ will automatically load the data and perform some\n",
    "# intiali transformations ans we describe. Than later we can use methods defined in the class to call other items example __getitem__\n",
    "# __len__\n",
    "\n",
    "\n",
    "# implement custom dataset.\n",
    "class WineDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        # Initialize data, download, etc.\n",
    "        # Data Loading: # read with numpy or pandas\n",
    "        xy = np.loadtxt('./data/wine.csv', delimeter=, ,dtype = np.float32, skiprows=1)\n",
    "        \n",
    "        # split whole dataset into x and y. Here the first column is the class label, the rest are the features\n",
    "        self.x = torch.from_numpy(xy[:, 1]) # all the rows except first, whcih is header\n",
    "        self.y = torch.from_numpy(xy[:, [0]]) # we put it in another array i.e, [0], n_samples, 1. So it makes task easy alter\n",
    "        self.n_samples = xy.shape[0] # first dimension is number of samples\n",
    "    \n",
    "    # support indexing such that dataset[i] can be used to get i-th sample\n",
    "    def __getitem__(self, index): \n",
    "        # Method Use for indexing support: This method allows indexing (dataset[i]) to get individual samples. \n",
    "        # Returns a tuple: (features, label).\n",
    "        return self.x[index], self.y[index] # this will return a tuple\n",
    "\n",
    "    # we can call len(dataset) to return the size\n",
    "    def __len__(self):\n",
    "        # len(dataset)\n",
    "        return self.n_samples\n",
    "\n",
    "# Create an object dataset from wineDataset\n",
    "dataset = WineDataset()\n",
    "\n",
    "# Look the dataset: Get first sample and unpack\n",
    "first_data = dataset[0]\n",
    "# unpack this in features and labels\n",
    "features, labels = first_data\n",
    "print(features, labels )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39af452b-f6f8-45f8-9a3c-42cb7b10d43c",
   "metadata": {},
   "source": [
    "### Understanding the Code\n",
    "This code defines a custom dataset class (WineDataset) using PyTorch’s Dataset class. It is used to load, preprocess, and access the Wine dataset.\n",
    "\n",
    "1. Importing Required Modules\n",
    "2. Defining the Custom Dataset Class\n",
    "    - Class Definition: `class WineDataset(Dataset):`\n",
    "        - Inherits from torch.utils.data.Dataset, allowing it to be used with PyTorch’s DataLoader.\n",
    "        - Provides functionality for indexing, retrieving items, and getting dataset length.\n",
    "    - `__init__` Method (Dataset Initialization): `def __init__(self):`\n",
    "        - This method is called when an object of the class is created. It loads and prepares the dataset.\n",
    "    - Data Loading:\n",
    "\n",
    "| Method              | Purpose                                                   |\n",
    "|---------------------|-----------------------------------------------------------|\n",
    "| `__init__()`       | Loads and prepares the dataset (reads CSV, splits into X & Y). |\n",
    "| `__getitem__(index)` | Allows indexing (`dataset[i]`) to retrieve data samples.   |\n",
    "| `__len__()`        | Returns the total number of samples (`len(dataset)`).      |\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "# Understanding `self`, `__init__`, and `super()` in Python\n",
    "\n",
    "## 1. `self` in Python Classes\n",
    "### **What is `self`?**\n",
    "- `self` represents the **instance of the class**.\n",
    "- It allows you to access **attributes and methods** inside the class.\n",
    "\n",
    "### **When to Use `self`?**\n",
    "- Inside class methods, use `self` to refer to instance variables.\n",
    "- Required when defining instance attributes in `__init__()`.\n",
    "- Used when calling other methods within the class.\n",
    "\n",
    "### **Example: Using `self`**\n",
    "```\n",
    "class Example:\n",
    "    def __init__(self, value):\n",
    "        self.value = value  # Assigning instance variable\n",
    "\n",
    "    def display(self):\n",
    "        print(f\"Value: {self.value}\")  # Accessing instance variable\n",
    "```\n",
    "\n",
    "--- \n",
    "## 2. __init__() - The Constructor Method\n",
    "\n",
    "### **What is __init__()?**\n",
    "- __init__() is the initializer or constructor in Python.\n",
    "- It is automatically called when an object is created.\n",
    "- Used to initialize instance variables.\n",
    "\n",
    "### **When to Use  `__init__()`?**\n",
    "When you want to set default values or initialize data for an object.\n",
    "\n",
    "### **Example: Using `__init__()`**\n",
    "\n",
    "```\n",
    "class Person:\n",
    "    def __init__(self, name, age):\n",
    "        self.name = name  # Assign instance variable\n",
    "        self.age = age\n",
    "\n",
    "# Creating an object automatically calls __init__\n",
    "person1 = Person(\"Alice\", 25)\n",
    "print(person1.name, person1.age)  # Output: Alice 25\n",
    "```\n",
    "\n",
    "### **Why Use __init__()?**\n",
    "- It helps set initial values for an object when it's created.\n",
    "- Without `__init__()`, instance variables would need to be set manually.\n",
    "\n",
    "---\n",
    "## 3. super() - Calling Parent Class Methods\n",
    "\n",
    "### **What is `super()`?**\n",
    "- `super()` is used to call methods from the parent class.\n",
    "- It is commonly used in inheritance to extend functionality.\n",
    "\n",
    "### **When to Use `super()`?**\n",
    "- When overriding a method in a subclass but still needing the parent class behavior.\n",
    "-  When extending an existing class without rewriting all functionalities.\n",
    "\n",
    "### **Example: Using `super()`**\n",
    "```\n",
    "class Parent:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "\n",
    "    def show(self):\n",
    "        print(f\"Parent Name: {self.name}\")\n",
    "\n",
    "class Child(Parent):\n",
    "    def __init__(self, name, age):\n",
    "        super().__init__(name)  # Call Parent's __init__\n",
    "        self.age = age\n",
    "\n",
    "    def show(self):\n",
    "        super().show()  # Call Parent's show method\n",
    "        print(f\"Child Age: {self.age}\")\n",
    "\n",
    "# Create object of Child class\n",
    "child1 = Child(\"Alice\", 10)\n",
    "child1.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0ad306-a5e4-4115-8c52-33d3cab9529e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataloader: Load whole dataset with DataLoader\n",
    "# shuffle: shuffle data, good for training\n",
    "# num_workers: faster loading with multiple subprocesses\n",
    "# !!! IF YOU GET AN ERROR DURING LOADING, SET num_workers TO 0 !!!\n",
    "\n",
    "train_loader  = DataLoader(dataset=dataset, batch_size=4, shuffle=True, num_workers=2)\n",
    "# num_workers make loading faster as its using multiple process\n",
    "\n",
    "# convert to an iterator and look at one random sample\n",
    "dataiter = iter(train_loader )\n",
    "data = dataiter.next()\n",
    "features, labels = data\n",
    "print(features, labels)\n",
    "\n",
    "# Dummy Training loop\n",
    "num_epochs = 2\n",
    "total_samples = len(dataset)\n",
    "n_iterations = math.ceil(total_samples/4)\n",
    "print(total_samples, n_iterations)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (inputs, labels) in enumerate(train_loader): # enumerate function gives us the index         \n",
    "        # here: 178 samples, batch_size = 4, n_iters=178/4=44.5 -> 45 iterations\n",
    "        # Run your training process.  # Forward + backwar + update weights\n",
    "        if (i+1) % 5 == 0:\n",
    "            print(f'Epoch: {epoch+1}/{num_epochs}, Step {i+1}/{n_iterations}| Inputs {inputs.shape} | Labels {labels.shape}')\n",
    "            # batch size is 4, 13 feateures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945a9c29-3df2-455d-8de3-f886436e4c7e",
   "metadata": {},
   "source": [
    "### Some other dataset in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0667a033-1255-4de9-b50a-e14d0a3299f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some famous datasets are available in torchvision.datasets\n",
    "# e.g. MNIST, Fashion-MNIST, CIFAR10, COCO\n",
    "\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data',\n",
    "                                           train=True, \n",
    "                                           transform=torchvision.transforms.ToTensor(),  \n",
    "                                           download=True)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset,\n",
    "                          batch_size=3,\n",
    "                          shuffle=True)\n",
    "\n",
    "# look at one random sample\n",
    "dataiter = iter(train_loader)\n",
    "data = next(dataiter)\n",
    "inputs, targets = data\n",
    "print(inputs.shape, targets.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a65584b-892f-416e-87df-dc94c9b7eef6",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center; font-size: 32px; font-weight: bold;\">\n",
    "    Dataset Transforms\n",
    "</div>\n",
    "How we can use dataset transforms together with the built-in Dataset class. Apply built-in transforms to images, arrays, and tensors. Or write your own custom Transform classes.\n",
    "\n",
    "- Dataset Transforms\n",
    "- Use built-in Transforms\n",
    "- Implement custom Transforms\n",
    "\n",
    "```\n",
    "Transforms can be applied to PIL images, tensors, ndarrays, or custom data\n",
    "during creation of the DataSet\n",
    "\n",
    "complete list of built-in transforms: \n",
    "https://pytorch.org/docs/stable/torchvision/transforms.html\n",
    "\n",
    "On Images\n",
    "---------\n",
    "CenterCrop, Grayscale, Pad, RandomAffine\n",
    "RandomCrop, RandomHorizontalFlip, RandomRotation\n",
    "Resize, Scale\n",
    "\n",
    "On Tensors\n",
    "----------\n",
    "LinearTransformation, Normalize, RandomErasing\n",
    "\n",
    "Conversion\n",
    "----------\n",
    "ToPILImage: from tensor or ndrarray\n",
    "ToTensor : from numpy.ndarray or PILImage\n",
    "\n",
    "Generic\n",
    "-------\n",
    "Use Lambda \n",
    "\n",
    "Custom\n",
    "------\n",
    "Write own class\n",
    "\n",
    "Compose multiple Transforms\n",
    "---------------------------\n",
    "composed = transforms.Compose([Rescale(256),\n",
    "                               RandomCrop(224)])\n",
    "```\n",
    "\n",
    "Earlier we used buid in dataset and data loader. We canpass build in data transfrom to dataset than apply some trasnfroms. In below transfrom we convert images to tensor. We can see different pytorch transforms at pytorch website https://pytorch.org/docs/stable/torchvision/transforms.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7824528-50cf-4a0b-8af9-db0d4d2d8fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "# Transform MNIST data to tenosr\n",
    "dataset = torhcvision.datasets.MNIST(\n",
    "    root='./data', transform=torchvision.transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ebe82b6-31d9-4452-8b10-9c58e0f4f6f2",
   "metadata": {},
   "source": [
    "Earlier we inplmeneted custom `WineDataset`. Now let's extend this class to support transform  and write our own transform classes. This code we implemented earlier, where we implemented ` __getitem__` and `__len__` method whcih allow indexing and length.\n",
    "```\n",
    "# implement custom WineDataset.\n",
    "class WineDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        xy = np.loadtxt('./data/wine.csv', delimeter=, ,dtype = np.float32, skiprows=1)\n",
    "        self.n_samples = xy.shape[0]\n",
    "\n",
    "        # note that we donot convert to tensor\n",
    "        self.x = torch.from_numpy(xy[:, 1]) \n",
    "        self.y = torch.from_numpy(xy[:, [0]]) \n",
    "    \n",
    "    def __getitem__(self, index): \n",
    "        return self.x[index], self.y[index] \n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "\n",
    "dataset= WineDataset()\n",
    "```\n",
    "Let's extend this dataset class to support transform arguments. We put that in `__init__(self, transform=None):`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894554a4-5a8b-4e51-a517-88bfc4aaad3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Last tutorial we implemented custome wine dataset \n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "\n",
    "class WineDataset(Dataset):\n",
    "\n",
    "    def __init__(self, transform=None): # Added  transform=None. transform is optional\n",
    "        xy = np.loadtxt('./data/wine/wine.csv', delimiter=',', dtype=np.float32, skiprows=1)\n",
    "        self.n_samples = xy.shape[0]\n",
    "\n",
    "        # note that we do not convert to tensor here\n",
    "        self.x_data = xy[:, 1:]\n",
    "        self.y_data = xy[:, [0]]\n",
    "\n",
    "        self.transform = transform # for transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        sample = self.x_data[index], self.y_data[index]\n",
    "\n",
    "        if self.transform: # if transform is not None\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "\n",
    "# Write our own transfrom and apply to our dataset\n",
    "# Lets create Custom Transform class. In last class we converted to tensor but now lets leave it to numpy array and pass to \n",
    "# dataset to convert to tensor. The only thing we need to change is to use implement __call__(self, sample)\n",
    "class ToTensor:\n",
    "    # Convert ndarrays to Tensors\n",
    "    def __call__(self, sample):  # callable object\n",
    "        inputs, targets = sample # unpack our samples\n",
    "        return torch.from_numpy(inputs), torch.from_numpy(targets)\n",
    "\n",
    "print('Without Transform')\n",
    "dataset = WineDataset()\n",
    "first_data = dataset[0]\n",
    "features, labels = first_data\n",
    "print(type(features), type(labels))\n",
    "print(features, labels)\n",
    "\n",
    "print('\\nWith Tensor Transform')\n",
    "dataset = WineDataset(transform=ToTensor())\n",
    "first_data = dataset[0]\n",
    "features, labels = first_data\n",
    "print(type(features), type(labels))\n",
    "print(features, labels)\n",
    "\n",
    "print('\\nWith None Transform')\n",
    "dataset = WineDataset(transform=None)\n",
    "first_data = dataset[0]\n",
    "features, labels = first_data\n",
    "print(type(features), type(labels))\n",
    "print(features, labels)\n",
    "\n",
    "# Write another custom transform to perform multiplicaiton\n",
    "class MulTransform:  # multiply inputs with a given factor\n",
    "    def __init__(self, factor):\n",
    "        self.factor = factor\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        inputs, targets = sample\n",
    "        inputs *= self.factor\n",
    "        return inputs, targets\n",
    "\n",
    "        \n",
    "print('\\nWith Tensor and Multiplication Transform')\n",
    "composed = torchvision.transforms.Compose([ToTensor(), MulTransform(4)])\n",
    "dataset = WineDataset(transform=composed)\n",
    "first_data = dataset[0]\n",
    "features, labels = first_data\n",
    "print(type(features), type(labels))\n",
    "print(features, labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
