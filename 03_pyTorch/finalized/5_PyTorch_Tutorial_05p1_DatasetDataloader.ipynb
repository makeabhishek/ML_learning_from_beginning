{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf81c5e6-fa4e-4df8-a836-37059d176c96",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center; font-size: 32px; font-weight: bold;\">\n",
    "    Dataset, DataLoader Classes, Dataset Transforms - Batch Training\n",
    "</div>\n",
    "\n",
    "we see how we can use the built-in `Dataset` and `DataLoader` classes and improve our pipeline with batch training. \n",
    "- Dataset and DataLoader\n",
    "- Automatic batch calculation\n",
    "- Batch optimization in training loop\n",
    "\n",
    "---\n",
    "\n",
    "#### Conventional Data loading\n",
    "So far our code is simple. \n",
    "- We loaded dataset from a csv file.\n",
    "- Ee have training loop.\n",
    "- We optimize the model based on whole dataset (Forward + Backward + weight Update). this can be time consuming if we do gradeint calcaulation on wholele data and sometimes inefficient to load full data at once. A better way for large datasets is to dovode the large samples in to small batches. \n",
    "\n",
    "```python\n",
    "data = numpy.loadtxt('wine.csv')\n",
    "# Training Loop\n",
    "for epoch in range(100):\n",
    "    X, y = data\n",
    "    # Forward + Backward + weight Update\n",
    "```\n",
    "---\n",
    "#### Batch Datasets\n",
    "In this case the trainingn loop will be\n",
    "```python\n",
    "# Training Loop\n",
    "for epoch in range(100):\n",
    "    # Loop over all batches\n",
    "    for i in range(total_batches):\n",
    "        X_batch, y_batch = ...\n",
    "        # We do optimization only for the current batch of data\n",
    "\n",
    "    # --> Use Dataset and Dataloader to load `wine.csv`\n",
    "```\n",
    "We can use PyTorch Dataset and Dataloader classes. It will do tha batch calcualtins and iterations.\n",
    "\n",
    "### Terminologies in batch training\n",
    "- epoch = one forward and backward pass of ALL training samples\n",
    "- batch_size = number of training samples used in one forward/backward pass\n",
    "- number of iterations = number of passes, each pass (forward+backward) using [batch_size] number of sampes\n",
    "- e.g : 100 samples, batch_size=20 -> 100/20=5 iterations for 1 epoch\n",
    "\n",
    "### --> DataLoader can do the batch computation for us\n",
    "```python\n",
    "# Implement a custom Dataset:\n",
    "# inherit Dataset\n",
    "implement __init__ , __getitem__ , and __len__\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d100c6e1-5117-431f-abba-cdd1a652f2d9",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (773188495.py, line 18)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[1], line 18\u001b[1;36m\u001b[0m\n\u001b[1;33m    xy = np.loadtxt('./data/wine.csv', delimeter=, ,dtype = np.float32, skiprows=1)\u001b[0m\n\u001b[1;37m                                                 ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader #  A base class for custom datasets in PyTorch.\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# Dataset: We have wine dataset.  \n",
    "# 1st row: Header\n",
    "# We want to predict wine categories. There are three wine categories: 1, 2, 3 so it means there are three classes or categories\n",
    "# The classes are in the first column and Features are in other columns\n",
    "\n",
    "# So here we are creating a custom dataset class, where `__init__` will automatically load the data and perform some\n",
    "# initial transformations as we describe. Than later we can use methods (functions) defined in the class to call other items example \n",
    "# `__getitem__` and `__len__`\n",
    "\n",
    "# implement custom dataset.\n",
    "class WineDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        # Initialize data, download, etc.\n",
    "        # Data Loading: # read with numpy or pandas\n",
    "        xy = np.loadtxt('./data/wine.csv', delimeter=, ,dtype = np.float32, skiprows=1)\n",
    "        \n",
    "        # split whole dataset into x and y. Here the first column is the class label, the rest are the features\n",
    "        self.x = torch.from_numpy(xy[:, 1]) # all the rows except first, whcih is header\n",
    "        self.y = torch.from_numpy(xy[:, [0]]) # we put it in another array i.e, [0], n_samples, 1. So it makes task easy alter\n",
    "        self.n_samples = xy.shape[0] # first dimension is number of samples\n",
    "    \n",
    "    # support indexing such that dataset[i] can be used to get i-th sample\n",
    "    def __getitem__(self, index): \n",
    "        # Method Use for indexing support: This method allows indexing (dataset[i]) to get individual samples. \n",
    "        # Returns a tuple: (features, label).\n",
    "        return self.x[index], self.y[index] # this will return a tuple\n",
    "\n",
    "    # we can call len(dataset) to return the size\n",
    "    def __len__(self):\n",
    "        # len(dataset)\n",
    "        return self.n_samples\n",
    "\n",
    "# Create an object dataset from wineDataset\n",
    "dataset = WineDataset()\n",
    "\n",
    "# Look the dataset: Get first sample and unpack\n",
    "first_data = dataset[0]\n",
    "# unpack this in features and labels\n",
    "features, labels = first_data\n",
    "print(features, labels )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0ad306-a5e4-4115-8c52-33d3cab9529e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataloader: Load whole dataset with DataLoader\n",
    "# shuffle: shuffle data, good for training\n",
    "# num_workers: faster loading with multiple subprocesses\n",
    "# !!! IF YOU GET AN ERROR DURING LOADING, SET num_workers TO 0 !!!\n",
    "\n",
    "train_loader  = DataLoader(dataset=dataset, batch_size=4, shuffle=True, num_workers=2)\n",
    "# num_workers make loading faster as its using multiple process\n",
    "\n",
    "# convert to an iterator and look at one random sample\n",
    "dataiter = iter(train_loader )\n",
    "data = dataiter.next()\n",
    "features, labels = data\n",
    "print(features, labels)\n",
    "\n",
    "# Dummy Training loop\n",
    "num_epochs = 2\n",
    "total_samples = len(dataset)\n",
    "n_iterations = math.ceil(total_samples/4)\n",
    "print(total_samples, n_iterations)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (inputs, labels) in enumerate(train_loader): # enumerate function gives us the index         \n",
    "        # here: 178 samples, batch_size = 4, n_iters=178/4=44.5 -> 45 iterations\n",
    "        # Run your training process.  # Forward + backwar + update weights\n",
    "        if (i+1) % 5 == 0:\n",
    "            print(f'Epoch: {epoch+1}/{num_epochs}, Step {i+1}/{n_iterations}| Inputs {inputs.shape} | Labels {labels.shape}')\n",
    "            # batch size is 4, 13 feateures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945a9c29-3df2-455d-8de3-f886436e4c7e",
   "metadata": {},
   "source": [
    "### Some other dataset in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0667a033-1255-4de9-b50a-e14d0a3299f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some famous datasets are available in torchvision.datasets\n",
    "# e.g. MNIST, Fashion-MNIST, CIFAR10, COCO\n",
    "\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data',\n",
    "                                           train=True, \n",
    "                                           transform=torchvision.transforms.ToTensor(),  \n",
    "                                           download=True)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset,\n",
    "                          batch_size=3,\n",
    "                          shuffle=True)\n",
    "\n",
    "# look at one random sample\n",
    "dataiter = iter(train_loader)\n",
    "data = next(dataiter)\n",
    "inputs, targets = data\n",
    "print(inputs.shape, targets.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a65584b-892f-416e-87df-dc94c9b7eef6",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center; font-size: 32px; font-weight: bold;\">\n",
    "    Dataset Transforms\n",
    "</div>\n",
    "How we can use dataset transforms together with the built-in Dataset class. Apply built-in transforms to images, arrays, and tensors. Or write your own custom Transform classes.\n",
    "\n",
    "- Dataset Transforms\n",
    "- Use built-in Transforms\n",
    "- Implement custom Transforms\n",
    "\n",
    "\n",
    "- Transforms can be applied to PIL images, tensors, ndarrays, or custom data during creation of the DataSet\n",
    "    - complete list of built-in transforms: https://pytorch.org/docs/stable/torchvision/transforms.html\n",
    "\n",
    "1. On Images: `CenterCrop`, `Grayscale`, `Pad`, `RandomAffine`, `RandomCrop`, `RandomHorizontalFlip`, `RandomRotation`, `Resize`, `Scale`\n",
    "\n",
    "2. On Tensors: `LinearTransformation`, `Normalize`, `RandomErasing`\n",
    "\n",
    "3. Conversion: `ToPILImage`: from tensor or ndrarray; `ToTensor` : from numpy.ndarray or PILImage\n",
    "\n",
    "4. Generic: Use `Lambda `\n",
    "\n",
    "5. Custom: Write own class\n",
    "\n",
    "6. Compose multiple Transforms: `composed = transforms.Compose([Rescale(256), RandomCrop(224)])`\n",
    "\n",
    "\n",
    "- Earlier we used buid in dataset and data loader. We canpass build in data transfrom to dataset than apply some trasnfroms. In below transfrom we convert images to tensor. We can see different pytorch transforms at pytorch website https://pytorch.org/docs/stable/torchvision/transforms.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7824528-50cf-4a0b-8af9-db0d4d2d8fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "# Transform MNIST data to tensor\n",
    "dataset = torhcvision.datasets.MNIST(\n",
    "    root='./data', transform=torchvision.transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ebe82b6-31d9-4452-8b10-9c58e0f4f6f2",
   "metadata": {},
   "source": [
    "Earlier we inplmeneted custom `WineDataset`. Now let's extend this class to support transform  and write our own transform classes. This code we implemented earlier, where we implemented ` __getitem__` and `__len__` method whcih allow indexing and length.\n",
    "```python\n",
    "# implement custom WineDataset.\n",
    "class WineDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        xy = np.loadtxt('./data/wine.csv', delimeter=, ,dtype = np.float32, skiprows=1)\n",
    "        self.n_samples = xy.shape[0]\n",
    "\n",
    "        # note that we donot convert to tensor\n",
    "        self.x = torch.from_numpy(xy[:, 1]) \n",
    "        self.y = torch.from_numpy(xy[:, [0]]) \n",
    "    \n",
    "    def __getitem__(self, index): \n",
    "        return self.x[index], self.y[index] \n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "\n",
    "dataset= WineDataset()\n",
    "```\n",
    "Let's extend this dataset class to support transform arguments. We put that in `__init__(self, transform=None):`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894554a4-5a8b-4e51-a517-88bfc4aaad3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Above we implemented custom wine dataset. Lets extend this with adding transforms\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "\n",
    "class WineDataset(Dataset):\n",
    "\n",
    "    def __init__(self, transform=None): # Added  transform=None. transform is optional\n",
    "        xy = np.loadtxt('./data/wine/wine.csv', delimiter=',', dtype=np.float32, skiprows=1)\n",
    "        self.n_samples = xy.shape[0]\n",
    "\n",
    "        # note that we do not convert to tensor here\n",
    "        self.x_data = xy[:, 1:]\n",
    "        self.y_data = xy[:, [0]]\n",
    "\n",
    "        self.transform = transform # for transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        sample = self.x_data[index], self.y_data[index]\n",
    "\n",
    "        if self.transform: # if transform is not None\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "\n",
    "# Write our own transform and apply to our dataset\n",
    "# Lets create Custom Transform class. In last class we converted to tensor but now lets leave it to numpy array and pass to \n",
    "# dataset to convert to tensor. The only thing we need to change is to use implement __call__(self, sample)\n",
    "class ToTensor:\n",
    "    # Convert ndarrays to Tensors\n",
    "    def __call__(self, sample):  # callable object\n",
    "        inputs, targets = sample # unpack our samples\n",
    "        return torch.from_numpy(inputs), torch.from_numpy(targets)\n",
    "\n",
    "print('Without Transform')\n",
    "dataset = WineDataset()\n",
    "first_data = dataset[0]\n",
    "features, labels = first_data\n",
    "print(type(features), type(labels))\n",
    "print(features, labels)\n",
    "\n",
    "print('\\nWith Tensor Transform')\n",
    "dataset = WineDataset(transform=ToTensor())\n",
    "first_data = dataset[0]\n",
    "features, labels = first_data\n",
    "print(type(features), type(labels))\n",
    "print(features, labels)\n",
    "\n",
    "print('\\nWith None Transform')\n",
    "dataset = WineDataset(transform=None)\n",
    "first_data = dataset[0]\n",
    "features, labels = first_data\n",
    "print(type(features), type(labels))\n",
    "print(features, labels)\n",
    "\n",
    "# Write another custom transform to perform multiplicaiton\n",
    "class MulTransform:  # multiply inputs with a given factor\n",
    "    def __init__(self, factor):\n",
    "        self.factor = factor\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        inputs, targets = sample\n",
    "        inputs *= self.factor\n",
    "        return inputs, targets\n",
    "\n",
    "        \n",
    "print('\\nWith Tensor and Multiplication Transform')\n",
    "composed = torchvision.transforms.Compose([ToTensor(), MulTransform(4)])\n",
    "dataset = WineDataset(transform=composed)\n",
    "first_data = dataset[0]\n",
    "features, labels = first_data\n",
    "print(type(features), type(labels))\n",
    "print(features, labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
